# üìä Como Visualizar M√©tricas e Dashboards

Guia passo a passo para acessar Prometheus, Grafana e visualizar as m√©tricas coletadas.

---

## üéØ Pr√©-requisitos

Certifique-se de que:
- ‚úÖ Cluster Kubernetes est√° rodando (`minikube status`)
- ‚úÖ Prometheus est√° instalado (`kubectl get pods -n monitoring`)
- ‚úÖ Aplica√ß√£o est√° deployada (`kubectl get pods -n pspd`)
- ‚úÖ ServiceMonitors est√£o configurados (`kubectl get servicemonitor -n pspd`)

---

## ‚ö†Ô∏è IMPORTANTE: Gera√ß√£o de M√©tricas

**As m√©tricas s√≥ aparecem quando h√° tr√°fego na aplica√ß√£o!**

- üìä **Prometheus coleta m√©tricas**, mas se ningu√©m est√° fazendo requisi√ß√µes, os valores ficam zerados ou inexistentes
- üöÄ **Para visualizar dados reais**: execute testes de carga ou fa√ßa requisi√ß√µes manuais
- ‚è±Ô∏è **Tempo de atualiza√ß√£o**: Prometheus faz scrape a cada 15-30 segundos

**Formas de gerar tr√°fego**:

1. **Testes de carga automatizados** (recomendado):
   ```bash
   k6 run load/spike.js       # Pico de tr√°fego (1min)
   k6 run load/baseline.js    # Carga constante (5min)
   k6 run load/soak.js        # Teste longo (10min)
   ```

2. **Requisi√ß√µes manuais**:
   ```bash
   # Abrir acesso ao Gateway
   kubectl port-forward -n pspd svc/p-svc 8080:80
   
   # Fazer requisi√ß√µes
   curl "http://localhost:8080/api/content?type=all"
   curl "http://localhost:8080/api/metadata/m1"
   curl "http://localhost:8080/api/browse?type=movies"
   ```

3. **Loop simples** (para testes):
   ```bash
   kubectl port-forward -n pspd svc/p-svc 8080:80 &
   while true; do curl -s "http://localhost:8080/api/content?type=all" > /dev/null; sleep 1; done
   ```

**Ap√≥s gerar tr√°fego, aguarde 15-30 segundos** para as m√©tricas aparecerem no Prometheus/Grafana.

---

## üìà Op√ß√£o 1: Prometheus (Visualiza√ß√£o de M√©tricas Brutas)

### Passo 1: Iniciar Port-Forward do Prometheus

Abra um terminal e execute:

```bash
kubectl port-forward -n monitoring svc/prometheus-kube-prometheus-prometheus 9090:9090
```

**Deixe este terminal aberto!** O comando ficar√° rodando.

### Passo 2: Acessar Interface Web

Abra seu navegador e acesse:
```
http://localhost:9090
```

### Passo 3: Verificar Targets (Servi√ßos Monitorados)

1. No Prometheus, clique em **Status** ‚Üí **Targets**
2. Procure pela se√ß√£o **`serviceMonitor/pspd/...`**
3. Voc√™ deve ver **3 targets UP** (verde):
   - `serviceMonitor/pspd/service-a-monitor/0` ‚Üí `10.x.x.x:9101`
   - `serviceMonitor/pspd/service-b-monitor/0` ‚Üí `10.x.x.x:9102`
   - `serviceMonitor/pspd/gateway-p-monitor/0` ‚Üí `10.x.x.x:8080`

#### ‚ö†Ô∏è Se N√ÉO aparecer nenhum target com `serviceMonitor/pspd`

**Causa**: ServiceMonitors n√£o foram criados ou Prometheus n√£o os descobriu ainda.

**Solu√ß√£o**:
```bash
# 1. Verificar se ServiceMonitors existem
kubectl get servicemonitor -n pspd

# Se retornar "No resources found":
# 2. Criar os ServiceMonitors
kubectl containerly -f k8s/servicemonitors.yaml

# 3. Aguardar 15-30 segundos e recarregar p√°gina do Prometheus
# 4. Verificar se apareceram em Status ‚Üí Targets
```

#### üî¥ Se targets aparecem mas est√£o DOWN (vermelho)

**Causa**: Pods n√£o est√£o rodando ou n√£o est√£o expondo m√©tricas corretamente.

**Solu√ß√£o**:
```bash
# 1. Verificar se pods est√£o Running
kubectl get pods -n pspd

# Se algum pod N√ÉO est√° Running:
# 2. Ver logs do pod com problema
kubectl logs -n pspd -l container=a  # para Service A
kubectl logs -n pspd -l container=b  # para Service B
kubectl logs -n pspd -l container=p  # para Gateway P

# 3. Reconstruir imagens e reiniciar pods
eval $(minikube -p minikube docker-env)
docker build -t a-service:local ./services/a_py
docker build -t b-service:local ./services/b_py
docker build -t p-gateway:local ./gateway_p_node

kubectl delete pod --all -n pspd
kubectl wait --for=condition=ready pod --all -n pspd --timeout=60s

# 4. Aguardar 15-30 segundos e verificar targets novamente
```

#### ‚úÖ Verificar se m√©tricas est√£o sendo expostas

```bash
# Testar endpoint de m√©tricas diretamente
kubectl exec -n pspd deploy/a-deploy -- python3 -c "import urllib.request; print(urllib.request.urlopen('http://localhost:9101/metrics').read().decode()[:500])"

# Se retornar erro, o servidor de m√©tricas n√£o est√° rodando
# Verifique os logs do pod para identificar o problema
```

### Passo 4: Explorar M√©tricas

**‚ö†Ô∏è LEMBRE-SE**: As queries abaixo s√≥ retornar√£o dados se houver tr√°fego na aplica√ß√£o!  
**Execute um teste de carga primeiro** (veja se√ß√£o "Gerar M√©tricas com Testes de Carga" abaixo).

No **Graph** (aba superior), teste estas queries:

#### Requisi√ß√µes HTTP por segundo (Gateway P)
```promql
rate(http_requests_total{container="p"}[1m])
```

#### Lat√™ncia P95 do Gateway
```promql
histogram_quantile(0.95, rate(http_request_duration_seconds_bucket{container="p"}[1m]))
```

#### Requisi√ß√µes gRPC do Service A
```promql
rate(grpc_server_requests_total{container="a"}[1m])
```

#### Itens streamed pelo Service B
```promql
rate(grpc_server_stream_items_total{container="b"}[1m])
```

#### CPU dos Pods
```promql
rate(container_cpu_usage_seconds_total{namespace="pspd"}[1m])
```

#### R√©plicas HPA
```promql
kube_horizontalpodautoscaler_status_current_replicas{namespace="pspd"}
```

**Dica**: Clique em **Execute** e depois em **Graph** para ver o gr√°fico!

---

## üé® Op√ß√£o 2: Grafana (Dashboards Visuais)

### Passo 1: Iniciar Port-Forward do Grafana

Abra um **novo terminal** e execute:

```bash
kubectl port-forward -n monitoring svc/prometheus-grafana 3000:80
```

**Deixe este terminal aberto!**

### Passo 2: Recuperar Senha do Grafana

Em outro terminal, execute:

```bash
kubectl get secret -n monitoring prometheus-grafana -o jsonpath="{.data.admin-password}" | base64 -d && echo
```

Copie a senha que aparecer (algo como: `RnoVJN3Y4KyzMfmgwExIzqiIXq90jEtgrqLNmBjb`)

### Passo 3: Fazer Login no Grafana

1. Abra seu navegador: http://localhost:3000
2. **Usu√°rio**: `admin`
3. **Senha**: Cole a senha copiada no passo anterior
4. Clique em **Log in**

### Passo 4: Explorar Dashboards Pr√©-instalados

No menu lateral, clique em **‚ò∞** ‚Üí **Dashboards**

Dashboards √∫teis para o projeto:

#### 1. **Kubernetes / Compute Resources / Namespace (Pods)**
- Mostra CPU e Mem√≥ria de todos os pods do namespace `pspd`
- Para ver suas m√©tricas: filtro superior ‚Üí namespace: `pspd`

#### 2. **Kubernetes / Compute Resources / Pod**
- M√©tricas detalhadas de um pod espec√≠fico
- Escolha pod: `a-deploy-xxx`, `b-deploy-xxx` ou `p-deploy-xxx`

#### 3. **Node Exporter / Nodes**
- M√©tricas dos n√≥s do cluster
- CPU, mem√≥ria, disco, rede

### Passo 5: Importar Dashboard Customizado da Aplica√ß√£o

1. No Grafana, clique em **‚ò∞** ‚Üí **Dashboards** ‚Üí **Import**
2. Clique em **Upload JSON file**
3. Selecione: `/home/edilberto/pspd/atividade-final-pspd/k8s/monitoring/grafana-dashboard.json`
4. Em **Prometheus**, selecione: **Prometheus** (deve ser a √∫nica op√ß√£o)
5. Clique em **Import**

**Dashboard inclui**:
- Taxa de requisi√ß√µes HTTP
- Lat√™ncia (P50, P95, P99)
- Taxa de erros
- N√∫mero de r√©plicas (HPA)
- CPU/Mem√≥ria por pod
- Throughput gRPC

### Passo 6: Criar Painel Customizado

1. Clique em **‚ò∞** ‚Üí **Dashboards** ‚Üí **New** ‚Üí **New Dashboard**
2. Clique em **Add visualization**
3. Selecione **Prometheus** como data source
4. Cole uma query PromQL (exemplos acima)
5. Configure:
   - **Title**: Nome descritivo
   - **Legend**: `{{pod}}` ou `{{container}}`
   - **Unit**: Escolha apropriada (req/s, ms, bytes, etc.)
6. Clique em **containerly**
7. **Save dashboard** (√≠cone de disquete no topo)

---

## üß™ Gerar M√©tricas com Testes de Carga

### Op√ß√£o 1: Testes de Carga Automatizados (K6)

Para ver as m√©tricas em a√ß√£o, execute testes de carga:

#### Terminal 1: Monitoramento em tempo real
```bash
./scripts/run_all_tests.sh monitor
```

#### Terminal 2: Port-forward da aplica√ß√£o
```bash
kubectl port-forward -n pspd svc/p-svc 8080:80
```

#### Terminal 3: Executar teste
```bash
BASE_URL=http://localhost:8080 ./scripts/run_all_tests.sh spike
```

Agora volte para **Grafana** ou **Prometheus** e veja as m√©tricas subindo em tempo real! üìà

---

### Op√ß√£o 2: Frontend Local + Backend Local (Fluxo Completo)

Execute a aplica√ß√£o frontend Next.js localmente conectada ao backend Kubernetes e observe m√©tricas em tempo real.

#### Passo 1: Preparar Ambiente

```bash
# Verificar se cluster est√° rodando
minikube status

# Verificar se aplica√ß√£o est√° deployada
kubectl get pods -n pspd
# Deve mostrar: a-deploy, b-deploy, p-deploy (todos Running)
```

#### Passo 2: Configurar Frontend

```bash
# No Windows, navegue para a pasta do frontend
# C:\Users\edilb\OneDrive\Documentos\streaming-container-design

# Criar arquivo de configura√ß√£o .env.local
# No PowerShell ou CMD:
echo NEXT_PUBLIC_API_URL=http://localhost:8081 > .env.local

# Instalar depend√™ncias (se ainda n√£o instalou)
npm install
```

**‚ö†Ô∏è IMPORTANTE**: Estamos usando porta `8081` para evitar conflito com outras aplica√ß√µes na porta 8080.

#### Passo 3: Iniciar Todos os Servi√ßos

Abra **4 terminais WSL (Ubuntu)** e execute em cada um:

**Terminal 1 - Backend (Port-forward)**:
```bash
cd /home/edilberto/pspd/atividade-final-pspd
kubectl port-forward -n pspd svc/p-svc 8081:80
```
**Deixe este terminal aberto e rodando!** Voc√™ ver√° mensagens como "Handling connection for 8081" quando o frontend fizer requisi√ß√µes.

**Terminal 2 - Prometheus**:
```bash
kubectl port-forward -n monitoring svc/prometheus-kube-prometheus-prometheus 9090:9090
```

**Terminal 3 - Grafana**:
```bash
kubectl port-forward -n monitoring svc/prometheus-grafana 3000:80
```

**Terminal 4 - Frontend (Next.js no Windows)**:
```powershell
# No PowerShell ou CMD do Windows
cd C:\Users\edilb\OneDrive\Documentos\streaming-container-design
npm run dev
```


#### Passo 4: Acessar Aplica√ß√µes

Aguarde ~10 segundos para todos os servi√ßos iniciarem, depois acesse:

1. **Frontend Next.js**: http://localhost:3001
   - Login: `emailcontateste@dominio.com`
   - Senha: `1234567890`

2. **Backend API**: http://localhost:8081
   - Teste: `curl http://localhost:8081/api/content?type=all`

3. **Prometheus**: http://localhost:9090
   - V√° em Graph e execute queries PromQL

4. **Grafana**: http://localhost:3000
   - Login: `admin` / senha do secret (veja Passo 2 da se√ß√£o Grafana acima)

#### Passo 5: Navegar no Frontend e Observar M√©tricas

1. **No Frontend** (http://localhost:3001):
   - Fa√ßa login
   - Clique em **Browse** ‚Üí **Movies**
   - Clique em **Browse** ‚Üí **Series**
   - Clique em **Browse** ‚Üí **Live TV**
   - Abra detalhes de alguns conte√∫dos

2. **No Prometheus** (http://localhost:9090/graph):
   
   Execute esta query e veja os dados atualizando:
   ```promql
   # Taxa de requisi√ß√µes em tempo real
   rate(http_requests_total{container="p"}[30s])
   
   # OU usando job (nome do servi√ßo)
   rate(http_requests_total{job="p-svc"}[1m])
   ```
   
   Outras queries √∫teis:
   ```promql
   # Requisi√ß√µes por endpoint
   sum by (route) (rate(http_requests_total{container="p"}[1m]))
   
   # Lat√™ncia P95
   histogram_quantile(0.95, rate(http_request_duration_seconds_bucket{container="p"}[1m]))
   
   # Total de requisi√ß√µes
   http_requests_total{container="p"}
   ```

   **‚ö†Ô∏è IMPORTANTE**: Use `container="p"` ou `job="p-svc"`, N√ÉO `container="p"`!  
   O Prometheus usa labels diferentes dos labels do Kubernetes.

3. **No Grafana** (http://localhost:3000):
   - Importe o dashboard: `k8s/monitoring/grafana-dashboard.json`
   - Veja gr√°ficos atualizando conforme voc√™ navega no frontend

#### Passo 6: Observar Logs em Tempo Real (Opcional)

Em um **5¬∫ terminal**, acompanhe os logs do Gateway P:

```bash
kubectl logs -n pspd -l container=p -f
```

Voc√™ ver√° cada requisi√ß√£o sendo processada quando navega no frontend:
```
GET /api/content?type=movies - 200 OK - 145ms
GET /api/metadata/m1 - 200 OK - 89ms
GET /api/browse?type=series - 200 OK - 123ms
```

#### Passo 7: Verificar M√©tricas Espec√≠ficas

**Consultas √∫teis no Prometheus**:

```promql
# Total de requisi√ß√µes nos √∫ltimos 5 minutos
sum(increase(http_requests_total{container="p"}[5m]))

# Endpoints mais acessados
topk(5, sum by (route) (rate(http_requests_total{container="p"}[5m])))

# Lat√™ncia m√©dia por endpoint
avg by (route) (rate(http_request_duration_seconds_sum{container="p"}[1m]) / rate(http_request_duration_seconds_count{container="p"}[1m]))

# CPU do Gateway P
rate(container_cpu_usage_seconds_total{namespace="pspd",pod=~"p-deploy.*"}[1m])
```

#### üéØ Fluxo Completo: Frontend ‚Üí Backend ‚Üí M√©tricas

```
Voc√™ navega no Frontend (localhost:3001)
         ‚Üì
Frontend faz fetch('/api/content')
         ‚Üì
Requisi√ß√£o HTTP ‚Üí Backend Gateway P (localhost:8081)
         ‚Üì
Gateway P converte HTTP ‚Üí gRPC
         ‚Üì
Service A (cat√°logo) ou Service B (metadata) responde
         ‚Üì
Gateway P incrementa m√©tricas Prometheus
         ‚Üì
Prometheus faz scrape das m√©tricas (a cada 15s)
         ‚Üì
Voc√™ v√™ m√©tricas atualizando no Prometheus/Grafana!
```

#### üêõ Troubleshooting Frontend Local

**Problema: "TypeError: clientA.GetContent is not a function"**

**Causa**: O arquivo `gateway_p_node/proto/services.proto` est√° desatualizado ou incorreto.

**Solu√ß√£o**:
```bash
# 1. Copiar proto correto
cp /home/edilberto/pspd/atividade-final-pspd/proto/services.proto \
   /home/edilberto/pspd/atividade-final-pspd/gateway_p_node/proto/services.proto

# 2. Rebuild imagem do Gateway P
eval $(minikube docker-env)
docker build -t p-gateway:local ./gateway_p_node

# 3. Reiniciar pod
kubectl delete pod -n pspd -l container=p
kubectl wait --for=condition=ready pod -n pspd -l container=p --timeout=60s
```

**Problema: Frontend n√£o conecta ao backend**

Verifique:
```bash
# 1. Backend est√° acess√≠vel?
curl http://localhost:8081/api/content?type=all

# 2. Arquivo .env.local existe? (no Windows)
# No PowerShell:
cat C:\Users\edilb\OneDrive\Documentos\streaming-container-design\.env.local
# Deve mostrar: NEXT_PUBLIC_API_URL=http://localhost:8081

# 3. Next.js est√° usando a vari√°vel?
# No navegador, abra DevTools ‚Üí Console e execute:
# console.log(process.env.NEXT_PUBLIC_API_URL)
```

**Problema: CORS error no navegador**

Se aparecer erro de CORS no console do navegador, adicione CORS no Gateway P:

```bash
# Ver se j√° tem CORS configurado
kubectl logs -n pspd -l container=p | grep -i cors

# Se necess√°rio, edite gateway_p_node/server.js e adicione:
# container.use(cors({ origin: 'http://localhost:3001' }))
# Depois rebuild: docker build -t p-gateway:local ./gateway_p_node
# E restart: kubectl delete pod -n pspd -l container=p
```

**Problema: M√©tricas n√£o aparecem**

```bash
# Verificar se est√° gerando tr√°fego
kubectl logs -n pspd -l container=p --tail=20

# Deve mostrar logs de requisi√ß√µes HTTP quando voc√™ navega
# Se n√£o aparecer, o frontend n√£o est√° fazendo requisi√ß√µes ao backend
```

#### ‚úÖ Checklist Frontend Local

- [ ] Port-forward do backend rodando (porta 8081 ‚Üí servi√ßo porta 80)
- [ ] Terminal mostra "Handling connection for 8081" quando frontend faz requisi√ß√µes
- [ ] Frontend Next.js rodando (porta 3001 no Windows)
- [ ] `.env.local` configurado com `NEXT_PUBLIC_API_URL=http://localhost:8081`
- [ ] Prometheus acess√≠vel (porta 9090)
- [ ] Grafana acess√≠vel (porta 3000)
- [ ] Login no frontend funciona
- [ ] Navega√ß√£o carrega conte√∫dos do backend
- [ ] Logs do Gateway P mostram requisi√ß√µes (veja Terminal 1)
- [ ] M√©tricas aparecem no Prometheus
- [ ] Dashboard Grafana atualiza em tempo real

**Se todos os itens est√£o ‚úÖ, o fluxo completo est√° funcionando!** üéâ

---

## üîç Verificar se M√©tricas Est√£o Sendo Coletadas

### M√©todo 1: Via Port-Forward Direto nos Pods

```bash
# Service A (porta 9101)
kubectl port-forward -n pspd svc/a-svc 9101:9101
curl http://localhost:9101/metrics | grep grpc_server

# Service B (porta 9102)
kubectl port-forward -n pspd svc/b-svc 9102:9102
curl http://localhost:9102/metrics | grep grpc_server

# Gateway P (porta 8080)
kubectl port-forward -n pspd svc/p-svc 8080:80
curl http://localhost:8080/metrics | grep http_requests
```

Deve aparecer algo como:
```
grpc_server_requests_total{method="GetContent",status="success"} 42.0
http_requests_total{method="GET",route="/api/content",status_code="200"} 156.0
```

### M√©todo 2: Via Prometheus Targets

1. Acesse Prometheus: http://localhost:9090/targets
2. Procure por `serviceMonitor/pspd`
3. Verifique:
   - **State**: UP (verde) ‚úÖ
   - **Last Scrape**: Recente (<1min)
   - **Scrape Duration**: Baixo (<100ms)

### M√©todo 3: Query no Prometheus

No Prometheus, execute:
```promql
up{namespace="pspd"}
```

Resultado esperado:
```
up{job="serviceMonitor/pspd/gateway-p-monitor/0", namespace="pspd"} = 1
up{job="serviceMonitor/pspd/service-a-monitor/0", namespace="pspd"} = 1
up{job="serviceMonitor/pspd/service-b-monitor/0", namespace="pspd"} = 1
```

**1 = UP ‚úÖ | 0 = DOWN ‚ùå**

---

## üìä Queries PromQL √öteis

### M√©tricas da Aplica√ß√£o

#### Taxa de Requisi√ß√µes HTTP
```promql
sum(rate(http_requests_total{namespace="pspd"}[1m])) by (container, route)
```

#### Lat√™ncia P95 por Endpoint
```promql
histogram_quantile(0.95, 
  sum(rate(http_request_duration_seconds_bucket{namespace="pspd"}[5m])) 
  by (le, route)
)
```

#### Taxa de Erro (HTTP 5xx)
```promql
sum(rate(http_requests_total{namespace="pspd",status_code=~"5.."}[1m])) 
/ 
sum(rate(http_requests_total{namespace="pspd"}[1m])) * 100
```

#### gRPC Request Rate (Service A)
```promql
rate(grpc_server_requests_total{container="a",status="success"}[1m])
```

#### Streaming Items/s (Service B)
```promql
rate(grpc_server_stream_items_total{container="b"}[1m])
```

### M√©tricas de Infraestrutura

#### CPU por Pod
```promql
sum(rate(container_cpu_usage_seconds_total{namespace="pspd"}[1m])) by (pod)
```

#### Mem√≥ria por Pod
```promql
sum(container_memory_working_set_bytes{namespace="pspd"}) by (pod) / 1024 / 1024
```

#### R√©plicas Atual vs Desejado (HPA)
```promql
kube_horizontalpodautoscaler_status_current_replicas{namespace="pspd"}
kube_horizontalpodautoscaler_spec_max_replicas{namespace="pspd"}
```

#### Network In/Out
```promql
rate(container_network_receive_bytes_total{namespace="pspd"}[1m])
rate(container_network_transmit_bytes_total{namespace="pspd"}[1m])
```

---

## üêõ Troubleshooting

### Problema: "No data points" no Grafana

**Causa**: M√©tricas ainda n√£o foram geradas (aplica√ß√£o n√£o recebeu tr√°fego)

**Solu√ß√£o - Op√ß√£o 1: Executar teste de carga** (recomendado):
```bash
# Teste r√°pido de 1 minuto
k6 run load/spike.js

# OU teste baseline de 5 minutos
k6 run load/baseline.js
```

**Solu√ß√£o - Op√ß√£o 2: Gerar tr√°fego manual**:
```bash
# Terminal 1: Abrir acesso
kubectl port-forward -n pspd svc/p-svc 8080:80

# Terminal 2: Fazer v√°rias requisi√ß√µes
for i in {1..50}; do
  curl -s "http://localhost:8080/api/content?type=all" > /dev/null
  curl -s "http://localhost:8080/api/metadata/m$i" > /dev/null
  curl -s "http://localhost:8080/api/browse?type=movies" > /dev/null
done

# Aguardar 15-30 segundos para Prometheus fazer scrape
```

### Problema: Targets DOWN no Prometheus

**Verificar pods**:
```bash
kubectl get pods -n pspd
```

**Se pods n√£o est√£o Running**:
```bash
# Ver logs
kubectl logs -n pspd -l container=a

# Reiniciar
kubectl delete pod --all -n pspd
kubectl wait --for=condition=ready pod --all -n pspd --timeout=60s
```

**Verificar ServiceMonitors**:
```bash
kubectl get servicemonitor -n pspd
kubectl describe servicemonitor service-a-monitor -n pspd
```

### Problema: Senha do Grafana n√£o funciona

**Resetar senha**:
```bash
# Deletar pod do Grafana para recriar
kubectl delete pod -n monitoring -l container.kubernetes.io/name=grafana

# Aguardar pod ficar pronto
kubectl wait --for=condition=ready pod -n monitoring -l container.kubernetes.io/name=grafana --timeout=60s

# Recuperar nova senha
kubectl get secret -n monitoring prometheus-grafana -o jsonpath="{.data.admin-password}" | base64 -d
```

### Problema: Port-forward para ou cai

**Usar script est√°vel** (mant√©m rodando):
```bash
./scripts/stable_port_forward.sh
```

Ou **manualmente** com loop:
```bash
while true; do
  kubectl port-forward -n monitoring svc/prometheus-grafana 3000:80
  echo "Port-forward caiu, reconectando em 5s..."
  sleep 5
done
```

---

## üìö Pr√≥ximos Passos

1. ‚úÖ Acesse Prometheus: http://localhost:9090
2. ‚úÖ Verifique targets est√£o UP: Status ‚Üí Targets
3. ‚úÖ Acesse Grafana: http://localhost:3000 (admin + senha do secret)
4. ‚úÖ Importe dashboard: `k8s/monitoring/grafana-dashboard.json`
5. ‚úÖ Execute teste de carga: `./scripts/run_all_tests.sh spike`
6. ‚úÖ Observe m√©tricas em tempo real no Grafana
7. ‚úÖ Explore queries PromQL no Prometheus

---

## üéØ Checklist de Valida√ß√£o

- [ ] Prometheus acess√≠vel em http://localhost:9090
- [ ] 3 targets UP no Prometheus (a, b, p)
- [ ] Grafana acess√≠vel em http://localhost:3000
- [ ] Dashboard customizado importado
- [ ] M√©tricas aparecem ap√≥s gerar tr√°fego
- [ ] HPA scaling vis√≠vel nos dashboards
- [ ] Lat√™ncia P95 < 200ms em baseline test

**Se todos os itens estiverem ‚úÖ, seu monitoramento est√° 100% funcional!** üéâ
