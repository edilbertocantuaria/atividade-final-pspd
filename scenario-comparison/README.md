# ğŸ“Š AnÃ¡lise Comparativa de CenÃ¡rios - VisualizaÃ§Ãµes

## VisÃ£o Geral

Esta pasta contÃ©m a anÃ¡lise comparativa completa entre os 5 cenÃ¡rios de teste implementados.

## ğŸ“ˆ GrÃ¡ficos Gerados

### 1. LatÃªncia P95 Comparison (`01_scenario_latency_comparison.png`)

**Esquerda**: Barras agrupadas mostrando latÃªncia P95 de cada cenÃ¡rio em cada tipo de teste (baseline, ramp, spike, soak).

**Direita**: Barras horizontais focadas no teste de spike, mostrando qual cenÃ¡rio teve melhor/pior latÃªncia sob stress.

**InterpretaÃ§Ã£o**:
- âœ… **Valores menores sÃ£o melhores**
- CenÃ¡rio 2 (2 rÃ©plicas) deve ter latÃªncia menor no baseline (warm start)
- CenÃ¡rio 4 (recursos limitados) tende a ter latÃªncia maior (throttling)
- CenÃ¡rio 5 (sem HPA) pode ter latÃªncia alta no spike (sem scaling)

---

### 2. Throughput Comparison (`02_scenario_throughput_comparison.png`)

**Esquerda**: Barras agrupadas mostrando throughput (req/s) de cada cenÃ¡rio.

**Direita**: Throughput mÃ©dio geral de cada cenÃ¡rio.

**InterpretaÃ§Ã£o**:
- âœ… **Valores maiores sÃ£o melhores**
- CenÃ¡rios com mais rÃ©plicas iniciais (2, 3, 5) devem ter throughput baseline maior
- CenÃ¡rio 5 (sem HPA) pode ter throughput consistente mas nÃ£o otimizado
- CenÃ¡rio 4 (recursos limitados) pode compensar com mais pods pequenos

---

### 3. HPA Scaling (`03_scenario_hpa_scaling.png`)

Mostra nÃºmero de rÃ©plicas de cada serviÃ§o (A, B, P) durante o teste de spike (200 VUs).

**InterpretaÃ§Ã£o**:
- âœ… **CenÃ¡rio 5 nÃ£o tem barras** (sem HPA = rÃ©plicas fixas)
- CenÃ¡rio 4 deve ter mais rÃ©plicas (compensa recursos limitados)
- Gateway P tende a escalar mais que Services A/B
- CenÃ¡rio 1 (base) Ã© referÃªncia para comparaÃ§Ã£o

---

### 4. Success Rate (`04_scenario_success_rate.png`)

4 subgrÃ¡ficos (baseline, ramp, spike, soak) mostrando taxa de sucesso de cada cenÃ¡rio.

**InterpretaÃ§Ã£o**:
- âœ… **Meta: â‰¥ 95%** (linha vermelha tracejada)
- Spike pode ter taxa menor em alguns cenÃ¡rios (stress extremo)
- CenÃ¡rio 4 pode ter taxa reduzida (CPU throttling, OOM)
- Baseline/soak devem estar prÃ³ximos de 100%

---

### 5. Cost Analysis (`05_scenario_cost_analysis.png`)

**Esquerda**: Pods ativos em diferentes fases (baseline, spike, mÃ©dia).

**Direita**: Custo total estimado (pod-horas) para executar todos os testes (~27min).

**InterpretaÃ§Ã£o**:
- âœ… **Valores menores sÃ£o mais econÃ´micos**
- CenÃ¡rio 5 (sem HPA) tem custo FIXO alto (~11 pods sempre)
- CenÃ¡rio 1 (base) Ã© referÃªncia (linha azul tracejada)
- CenÃ¡rio 4 pode ter custo similar ao base (mais pods pequenos)
- CenÃ¡rios 2-3 tÃªm custo inicial maior mas justificado por performance/HA

**AnÃ¡lise de Custo**:
```
CenÃ¡rio 1 (Base):     ~2.7 pod-horas (baseline)
CenÃ¡rio 2 (RÃ©plicas): ~3.6 pod-horas (+33%)
CenÃ¡rio 3 (Distrib.): ~5.0 pod-horas (+85%)
CenÃ¡rio 4 (Recursos): ~4.0 pod-horas (+48%)
CenÃ¡rio 5 (Sem HPA):  ~4.9 pod-horas (+81%)
```

---

### 6. Performance Radar (`06_scenario_performance_radar.png`)

Radar chart multi-dimensional comparando 5 aspectos:
- **Throughput**: Req/s geral
- **LatÃªncia P95**: Inverso (menor Ã© melhor)
- **Success Rate**: Taxa de sucesso
- **Custo**: Inverso (menor custo = mais estrelas)
- **HA (High Availability)**: ResiliÃªncia e distribuiÃ§Ã£o

**InterpretaÃ§Ã£o**:
- âœ… **5 estrelas = excelente** em cada dimensÃ£o
- Ãrea maior = cenÃ¡rio mais equilibrado
- Ãštil para visualizar trade-offs

**Scores esperados**:
```
CenÃ¡rio 1 (Base):        Equilibrado (4 estrelas na maioria)
CenÃ¡rio 2 (RÃ©plicas):    Alto throughput/latÃªncia, custo mÃ©dio
CenÃ¡rio 3 (DistribuÃ­do): HA excelente, custo alto
CenÃ¡rio 4 (Recursos):    Custo bom, performance reduzida
CenÃ¡rio 5 (Sem HPA):     Performance boa, custo pÃ©ssimo, HA baixo
```

---

## ğŸ“„ RelatÃ³rios Textuais

### `SCENARIO_COMPARISON_REPORT.txt`

RelatÃ³rio completo com:
- MÃ©tricas detalhadas de cada cenÃ¡rio (baseline, ramp, spike, soak)
- Dados de HPA scaling
- Tabela comparativa resumida do spike test

**Exemplo de saÃ­da**:
```
Spike Test (200 VUs):
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
CenÃ¡rio                   Throughput        P95    Success     Pods
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
S1: Base (HPA)              422.9/s      999ms     100.0%        11
S2: 2 RÃ©plicas              450.3/s      850ms     100.0%        13
S3: DistribuÃ­do             410.2/s     1100ms      98.5%        15
S4: Recursos -50%           380.5/s     1450ms      95.2%        18
S5: Sem HPA                 420.1/s     1050ms      92.3%        11
```

### `comparison-summary.md`

Markdown com mÃ©tricas extraÃ­das do SUMMARY_REPORT.txt de cada cenÃ¡rio.

---

## ğŸ¯ Como Interpretar a AnÃ¡lise

### Melhor CenÃ¡rio para Cada Objetivo

| Objetivo | CenÃ¡rio Recomendado | Motivo |
|----------|---------------------|--------|
| **Melhor Performance** | CenÃ¡rio 2 (RÃ©plicas) | Warm start, menor latÃªncia |
| **Menor Custo** | CenÃ¡rio 1 (Base) | Otimizado pelo HPA |
| **Alta Disponibilidade** | CenÃ¡rio 3 (DistribuÃ­do) | Pods em diferentes nodes |
| **Recursos Limitados** | CenÃ¡rio 4 | Funciona com 50% menos recursos |
| **Simplicidade** | CenÃ¡rio 5 (Sem HPA) | PrevisÃ­vel mas caro |

### Trade-offs Principais

#### CenÃ¡rio 1 (Base) - â­â­â­â­
âœ… **Pros**: Equilibrado, bom custo/benefÃ­cio, HPA otimiza automaticamente  
âŒ **Cons**: Cold start no baseline

#### CenÃ¡rio 2 (2 RÃ©plicas) - â­â­â­â­â­
âœ… **Pros**: Melhor latÃªncia baseline, warm start, throughput alto  
âŒ **Cons**: +33% de custo baseline

#### CenÃ¡rio 3 (DistribuÃ­do) - â­â­â­â­
âœ… **Pros**: Alta disponibilidade, resiliente a falhas de node  
âŒ **Cons**: +85% custo, possÃ­vel latÃªncia inter-node

#### CenÃ¡rio 4 (Recursos Limitados) - â­â­â­
âœ… **Pros**: Funciona com metade dos recursos, HPA compensa  
âŒ **Cons**: CPU throttling, latÃªncia maior, mais pods necessÃ¡rios

#### CenÃ¡rio 5 (Sem HPA) - â­â­
âœ… **Pros**: Simples, previsÃ­vel, sem cold start  
âŒ **Cons**: +81% custo, over-provisioning, sem elasticidade

---

## ğŸš€ Gerando AnÃ¡lise

### AutomÃ¡tico (apÃ³s executar cenÃ¡rios)
```bash
./scripts/run_scenario_comparison.sh --all
# Gera automaticamente ao final
```

### Manual (cenÃ¡rios jÃ¡ executados)
```bash
./scripts/run_scenario_comparison.sh --compare
# Ou diretamente:
python3 scripts/compare_scenarios.py
```

---

## ğŸ“Š Requisitos

- Python 3.8+
- matplotlib (`pip3 install matplotlib`)
- Resultados dos cenÃ¡rios em `results-scenario-{1-5}/`

---

## ğŸ“ ConclusÃ£o Esperada

A anÃ¡lise comparativa deve demonstrar:

1. **HPA Ã© essencial**: CenÃ¡rio 5 (sem HPA) Ã© 81% mais caro com performance similar
2. **Warm start vale a pena**: CenÃ¡rio 2 tem melhor latÃªncia por +33% custo
3. **HA tem custo**: CenÃ¡rio 3 oferece resiliÃªncia por +85% custo
4. **Recursos limitados funcionam**: CenÃ¡rio 4 compensa com mais pods
5. **Trade-offs claros**: NÃ£o hÃ¡ "melhor cenÃ¡rio", depende do objetivo

**RecomendaÃ§Ã£o geral**: CenÃ¡rio 1 (Base) ou 2 (RÃ©plicas) para produÃ§Ã£o, com HPA sempre habilitado.
