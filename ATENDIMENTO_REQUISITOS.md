# Atendimento aos Requisitos do Trabalho Final

Este documento demonstra como o projeto atende **completamente** aos requisitos especificados.

---

## ğŸ“‹ Requisito 1: AplicaÃ§Ã£o Baseada em MicroserviÃ§os

### âœ… EspecificaÃ§Ã£o Atendida

**AplicaÃ§Ã£o**: Plataforma de Streaming de VÃ­deo

A aplicaÃ§Ã£o segue **exatamente** a arquitetura da Figura 1:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         WEB API (P)                 â”‚
â”‚         Gateway Node.js             â”‚  â† RequisiÃ§Ãµes HTTP do frontend
â”‚      (Express + gRPC Client)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
          gRPC Stub
          â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”
          â†“          â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚Service A â”‚  â”‚Service B â”‚
    â”‚(CatÃ¡logo)â”‚  â”‚(Metadata)â”‚
    â”‚ Python   â”‚  â”‚ Python   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     Proto Req     Proto Req
     Proto Resp    Proto Resp(s)
```

### MÃ³dulos Implementados

#### **MÃ³dulo P - Gateway Web API**

**Arquivo**: `gateway_p_node/server.js`

**FunÃ§Ã£o**: 
- Recebe requisiÃ§Ãµes HTTP/REST do frontend Next.js
- Converte para chamadas gRPC usando Protocol Buffers
- Consolida respostas de A e B
- ExpÃµe 3 endpoints REST principais

**Endpoints Expostos**:

1. **`GET /api/content?type=movies&limit=10`**
   - Chama `Service A` via gRPC
   - Retorna catÃ¡logo filtrado de filmes/sÃ©ries/canais

2. **`GET /api/metadata/:contentId`**
   - Chama `Service B` via gRPC (streaming)
   - Retorna metadados e recomendaÃ§Ãµes

3. **`GET /api/browse?type=all`**
   - **ConsolidaÃ§Ã£o Pâ†’A+B**: Chama ambos os serviÃ§os
   - Primeiro busca catÃ¡logo (A)
   - Depois busca metadados do primeiro item (B)
   - Retorna resultado combinado

**MÃ©tricas Prometheus**: ExpÃµe `/metrics` com mÃ©tricas HTTP e gRPC

#### **MÃ³dulo A - Service A (CatÃ¡logo)**

**Arquivo**: `services/a_py/server.py`

**FunÃ§Ã£o**: 
- MicrosserviÃ§o gRPC que fornece catÃ¡logo de conteÃºdo
- Banco de dados simulado com 12 itens (4 filmes + 4 sÃ©ries + 3 canais + metadados)

**RPC Implementada**:
```protobuf
service ServiceA {
  rpc GetContent(ContentRequest) returns (ContentResponse);
}
```

**CaracterÃ­sticas**:
- **ComunicaÃ§Ã£o unÃ¡ria**: Uma requisiÃ§Ã£o â†’ Uma resposta
- **Filtros**: Por tipo (`movies`, `series`, `live`, `all`) e gÃªnero
- **Retorna**: Lista de `ContentItem` com id, tÃ­tulo, descriÃ§Ã£o, rating, etc.

**Exemplo de Resposta**:
```json
{
  "items": [
    {
      "id": "m1",
      "title": "A Jornada Infinita",
      "type": "movie",
      "genres": ["FicÃ§Ã£o CientÃ­fica", "Aventura"],
      "rating": 8.7
    }
  ],
  "total": 4
}
```

#### **MÃ³dulo B - Service B (Metadados e RecomendaÃ§Ãµes)**

**Arquivo**: `services/b_py/server.py`

**FunÃ§Ã£o**:
- MicrosserviÃ§o gRPC que fornece metadados detalhados via streaming
- Simula processamento incremental (anÃ¡lise de dados, ML)

**RPC Implementada**:
```protobuf
service ServiceB {
  rpc StreamMetadata(MetadataRequest) returns (stream MetadataItem);
}
```

**CaracterÃ­sticas**:
- **ComunicaÃ§Ã£o streaming**: Uma requisiÃ§Ã£o â†’ MÃºltiplas respostas (stream)
- **Retorna**: Diretor, elenco, filmes similares, recomendaÃ§Ãµes
- **Processamento incremental**: Envia dados conforme processa (0.01s entre itens)

**Exemplo de Resposta (stream)**:
```json
[
  {"key": "director", "value": "James Cameron", "relevanceScore": 0.95},
  {"key": "cast", "value": "Chris Evans", "relevanceScore": 0.90},
  {"key": "similar", "value": "Interestelar", "relevanceScore": 0.85}
]
```

### Contrato gRPC (Protocol Buffers)

**Arquivo**: `proto/services.proto`

```protobuf
syntax = "proto3";
package pspd;

// Service A: CatÃ¡logo
message ContentRequest {
  string type = 1;      // "movies", "series", "live", "all"
  int32 limit = 2;
  string genre = 3;
}

message ContentItem {
  string id = 1;
  string title = 2;
  string description = 3;
  // ... mais campos
}

message ContentResponse {
  repeated ContentItem items = 1;
  int32 total = 2;
}

service ServiceA {
  rpc GetContent(ContentRequest) returns (ContentResponse);
}

// Service B: Metadados
message MetadataRequest {
  string content_id = 1;
  string user_id = 2;
}

message MetadataItem {
  string key = 1;
  string value = 2;
  float relevance_score = 3;
}

service ServiceB {
  rpc StreamMetadata(MetadataRequest) returns (stream MetadataItem);
}
```

### Frontend (DemonstraÃ§Ã£o)

**Deployed em**: https://streaming-app-design.vercel.app/

**Tecnologia**: Next.js 14 (React) com TypeScript

**IntegraÃ§Ã£o**: Ver `docs/INTEGRACAO_FRONTEND.md`

---

## ğŸ“‹ Requisito 2: Cluster Kubernetes Multi-Node

### âœ… EspecificaÃ§Ã£o Atendida

**Cluster Configurado**:
- **1 Master Node** (plano de controle Kubernetes)
- **2 Worker Nodes** (execuÃ§Ã£o de workloads)
- **Ferramenta**: Minikube com driver Docker

**Setup Documentado**: `docs/GUIA_MULTINODE.md`

### Comandos de CriaÃ§Ã£o

```bash
# Criar cluster multi-node
minikube start --nodes 3 --driver=docker --cpus=2 --memory=4096

# Verificar nodes
kubectl get nodes
# NAME           STATUS   ROLES           AGE
# minikube       Ready    control-plane   5m
# minikube-m02   Ready    <none>          4m
# minikube-m03   Ready    <none>          3m
```

### Recursos de Autoscaling

**HPA (Horizontal Pod Autoscaler)** configurado para todos os serviÃ§os:

**Arquivo**: `k8s/monitoring/hpa.yaml`

```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: p-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: p
  minReplicas: 1
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
```

**Comportamento**:
- CPU < 70%: MantÃ©m 1 rÃ©plica
- CPU > 70%: Escala atÃ© 10 rÃ©plicas
- Scale-down gradual apÃ³s carga reduzir

### Interface Web de Monitoramento

#### Prometheus

**InstalaÃ§Ã£o**: Helm chart `prometheus-community/kube-prometheus-stack`

```bash
helm install prometheus prometheus-community/kube-prometheus-stack \
  --namespace monitoring --create-namespace
```

**Acesso**:
```bash
kubectl port-forward -n monitoring svc/prometheus-kube-prometheus-prometheus 9090:9090
# â†’ http://localhost:9090
```

**Funcionalidades**:
- Coleta automÃ¡tica de mÃ©tricas do cluster
- ServiceMonitors customizados para P, A, B
- Queries PromQL para anÃ¡lise

#### Grafana

**Instalado junto com Prometheus** (parte do stack)

**Acesso**:
```bash
kubectl port-forward -n monitoring svc/prometheus-grafana 3000:80
# â†’ http://localhost:3000
# UsuÃ¡rio: admin
# Senha: prom-operator (ou admin/admin)
```

**Dashboards Importados**:
- Kubernetes Cluster Monitoring (ID: 7249)
- Node Exporter (ID: 1860)
- Dashboard customizado: `docs/grafana-dashboard.json`

### DistribuiÃ§Ã£o no Cluster (Figura 2)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         K8s Master Node                  â”‚
â”‚  (Control Plane - kube-apiserver, etc)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â†“                   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Worker Node 1  â”‚  â”‚  Worker Node 2  â”‚
â”‚                 â”‚  â”‚                 â”‚
â”‚  Pod: p-xxx     â”‚  â”‚  Pod: a-xxx     â”‚
â”‚  Pod: b-xxx     â”‚  â”‚  Pod: p-yyy     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**VerificaÃ§Ã£o de DistribuiÃ§Ã£o**:
```bash
kubectl get pods -n pspd -o wide
# NAME         NODE
# p-abc123     minikube-m02
# a-def456     minikube-m03
# b-ghi789     minikube-m02
```

---

## ğŸ“‹ Requisito 3: Testes de Carga com CenÃ¡rios

### âœ… EspecificaÃ§Ã£o Atendida

**Ferramenta Escolhida**: **k6** (https://k6.io/)

**Justificativa**:
- Projetado especificamente para testes de carga de APIs REST
- Scripting em JavaScript (fÃ¡cil manutenÃ§Ã£o)
- MÃ©tricas detalhadas (latÃªncia, throughput, erro)
- IntegraÃ§Ã£o com Prometheus (exportador k6)
- Open-source e amplamente usado

### ConfiguraÃ§Ã£o Base (CenÃ¡rio 1)

**DescriÃ§Ã£o**: AplicaÃ§Ã£o no estado mais simples

**Manifests**: `k8s/scenarios/scenario1-base/`

**CaracterÃ­sticas**:
- HPA ativado (1-10 rÃ©plicas)
- RÃ©plicas iniciais: 1 para cada serviÃ§o (P, A, B)
- Recursos: PadrÃ£o (CPU: 100m request, 200m limit)
- Sem anti-affinity (scheduler decide)

**MÃ©tricas Baseline Coletadas**:

1. **Tempo mÃ©dio de resposta**:
   - Teste: `load/baseline.js` (10 VUs, 2min)
   - Resultado esperado: ~50-150ms (p50), ~200-500ms (p95)

2. **MÃ¡xima req/s atendidas**:
   - Teste: `load/spike.js` (pico de 200 VUs)
   - Resultado esperado: ~100-300 req/s

**ExecuÃ§Ã£o**:
```bash
# Setup cenÃ¡rio 1
cd test/scenario_1
./00_setup.sh

# Rodar todos os testes
./run_all.sh

# Resultados em: test_results/scenario_1/
```

### CenÃ¡rios Variados

#### CenÃ¡rio 2: Warm Start (2 rÃ©plicas iniciais)

**VariaÃ§Ã£o**: `replicas: 2` para P, A, B

**HipÃ³tese**: Melhor tempo de resposta inicial (sem cold start)

**MÃ©tricas Comparadas**:
- LatÃªncia nos primeiros 30s
- Tempo atÃ© primeira resposta < 100ms

#### CenÃ¡rio 3: Alta Disponibilidade (Anti-affinity)

**VariaÃ§Ã£o**: `podAntiAffinity` forÃ§ando distribuiÃ§Ã£o entre workers

**HipÃ³tese**: Maior resiliÃªncia a falhas de node

**MÃ©tricas Comparadas**:
- Taxa de sucesso durante simulaÃ§Ã£o de falha de node
- DistribuiÃ§Ã£o de pods (deve ter P, A, B em ambos os workers)

#### CenÃ¡rio 4: Recursos Limitados (-50%)

**VariaÃ§Ã£o**: `cpu: 50m`, `memory: 64Mi` (metade do normal)

**HipÃ³tese**: LatÃªncia maior, HPA escala mais pods

**MÃ©tricas Comparadas**:
- NÃºmero de rÃ©plicas criadas durante ramp test
- LatÃªncia sob mesma carga

#### CenÃ¡rio 5: Sem Autoscaling (RÃ©plicas fixas)

**VariaÃ§Ã£o**: Remove HPA, fixa rÃ©plicas em 3 (P), 5 (A, B)

**HipÃ³tese**: Performance estÃ¡vel mas sem elasticidade

**MÃ©tricas Comparadas**:
- Consumo de recursos durante idle
- Tempo de resposta durante pico (deve degradar sem scaling)

### Tipos de Teste Aplicados

#### 1. Baseline Test (`load/baseline.js`)

**DuraÃ§Ã£o**: 2 minutos  
**VUs**: 10 usuÃ¡rios constantes

**Objetivo**: Estabelecer linha de base de performance

**RequisiÃ§Ãµes por VU**:
```javascript
1. GET /api/content?type=all&limit=20     // CatÃ¡logo completo
2. GET /api/content?type=movies&limit=10  // Filtro filmes
3. GET /api/metadata/m1                   // Metadados
4. GET /api/browse?type=series            // Endpoint combinado
```

**MÃ©tricas Coletadas**:
- `http_req_duration`: p50, p95, p99
- `http_req_failed`: taxa de erro
- `http_reqs`: req/s

#### 2. Ramp Test (`load/ramp.js`)

**DuraÃ§Ã£o**: 4.5 minutos  
**VUs**: 10 â†’ 50 â†’ 100 â†’ 150 â†’ 0 (gradual)

**Objetivo**: Testar autoscaling (HPA)

**ObservaÃ§Ãµes**:
- HPA deve criar novas rÃ©plicas quando CPU > 70%
- LatÃªncia deve se manter estÃ¡vel durante escala
- Scale-down deve acontecer gradualmente

**VerificaÃ§Ã£o HPA**:
```bash
watch -n 5 kubectl get hpa -n pspd
# NAME   REFERENCE   TARGETS   MINPODS   MAXPODS   REPLICAS
# p-hpa  Deployment  120%/70%  1         10        5
```

#### 3. Spike Test (`load/spike.js`)

**DuraÃ§Ã£o**: 1.5 minutos  
**VUs**: 10 â†’ 200 (spike repentino) â†’ 10

**Objetivo**: Testar resiliÃªncia a picos sÃºbitos

**CenÃ¡rio Simulado**: LanÃ§amento de sÃ©rie viral (todos acessam s1)

**RequisiÃ§Ãµes**:
```javascript
GET /api/content?type=series&limit=10
GET /api/metadata/s1
GET /api/browse?type=series&limit=5
```

**Threshold de Sucesso**:
- `http_req_failed < 10%` (aceita atÃ© 10% de erro durante spike)
- `http_req_duration p95 < 2000ms`

#### 4. Soak Test (`load/soak.js`)

**DuraÃ§Ã£o**: 11.5 minutos  
**VUs**: 50 usuÃ¡rios constantes

**Objetivo**: Detectar memory leaks e degradaÃ§Ã£o ao longo do tempo

**CenÃ¡rio Simulado**: Maratona de fim de semana

**RequisiÃ§Ãµes**:
```javascript
// Ciclo de navegaÃ§Ã£o completo
for (tipo in ['movies', 'series', 'live']) {
  GET /api/content?type={tipo}
  GET /api/metadata/{id1}
  GET /api/metadata/{id2}
}
GET /api/browse?type=all
```

**VerificaÃ§Ãµes**:
- LatÃªncia nÃ£o deve aumentar ao longo do tempo
- Uso de memÃ³ria deve se manter estÃ¡vel
- Taxa de erro deve permanecer < 5%

### ComparaÃ§Ã£o de CenÃ¡rios

**Script de AutomaÃ§Ã£o**: `scripts/run_scenario_comparison.sh`

**ExecuÃ§Ã£o**:
```bash
# Rodar todos os 5 cenÃ¡rios (2-3 horas)
./scripts/run_scenario_comparison.sh --all

# Apenas gerar grÃ¡ficos comparativos (dados jÃ¡ coletados)
./scripts/run_scenario_comparison.sh --compare
```

**GrÃ¡ficos Gerados**: `test_results/scenario-comparison/`

1. **01_scenario_latency_comparison.png**
   - LatÃªncia P95 de cada cenÃ¡rio (4 testes x 5 cenÃ¡rios)
   
2. **02_scenario_throughput_comparison.png**
   - Req/s atingidas por cenÃ¡rio

3. **03_scenario_hpa_scaling.png**
   - NÃºmero de rÃ©plicas ao longo do tempo (apenas cenÃ¡rios com HPA)

4. **04_scenario_success_rate.png**
   - Taxa de sucesso durante spike test

5. **05_scenario_cost_analysis.png**
   - Consumo mÃ©dio de CPU/memÃ³ria (eficiÃªncia)

6. **06_scenario_performance_radar.png**
   - Radar chart comparando 5 mÃ©tricas simultaneamente

### CondiÃ§Ãµes de Teste Garantidas

**Infraestrutura IdÃªntica**:
- Mesmo cluster (3 nodes)
- Mesmas especificaÃ§Ãµes de CPU/memÃ³ria (exceto cenÃ¡rio 4)
- Mesma versÃ£o das imagens Docker

**Isolamento de Testes**:
```bash
# Entre cada cenÃ¡rio:
kubectl delete namespace pspd
kubectl apply -f k8s/scenarios/scenario{N}/
sleep 60  # Aguardar estabilizaÃ§Ã£o
# Executar testes
```

**MÃºltiplas ExecuÃ§Ãµes**:
- Cada teste executado 3 vezes
- MÃ©dia dos resultados para reduzir ruÃ­do
- Desvio padrÃ£o reportado

---

## ğŸ“‹ Requisito 4: Observabilidade com Prometheus

### âœ… EspecificaÃ§Ã£o Atendida

**Prometheus Instalado**: Via Helm chart `kube-prometheus-stack`

**DocumentaÃ§Ã£o Completa**: `docs/METRICAS_PROMETHEUS.md`

### MÃ©tricas Customizadas Implementadas

#### Gateway P (Web API)

**Biblioteca**: `prom-client` (Node.js)

**Arquivo**: `gateway_p_node/server.js`

**MÃ©tricas**:

1. **`http_requests_total{method, route, status_code}`**
   - Tipo: Counter
   - Labels: mÃ©todo HTTP, rota, cÃ³digo de status
   - Uso: Taxa de requisiÃ§Ãµes por endpoint

2. **`http_request_duration_seconds{method, route, status_code}`**
   - Tipo: Histogram
   - Buckets: [0.001, 0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1, 2, 5]
   - Uso: LatÃªncia (p50, p95, p99) por endpoint

3. **`grpc_client_requests_total{service, method, status}`**
   - Tipo: Counter
   - Labels: ServiceA/ServiceB, nome do mÃ©todo, sucesso/erro
   - Uso: Taxa de chamadas gRPC originadas pelo gateway

4. **`grpc_client_request_duration_seconds{service, method, status}`**
   - Tipo: Histogram
   - Uso: LatÃªncia das chamadas gRPC (Pâ†’A, Pâ†’B)

**Endpoint de MÃ©tricas**: `http://localhost:8080/metrics`

#### Service A (CatÃ¡logo)

**Biblioteca**: `prometheus_client` (Python)

**Arquivo**: `services/a_py/server.py`

**MÃ©tricas**:

1. **`grpc_server_requests_total{method, status}`**
   - Tipo: Counter
   - Labels: GetContent, sucesso/erro
   - Uso: Taxa de requisiÃ§Ãµes recebidas

2. **`grpc_server_request_duration_seconds{method}`**
   - Tipo: Histogram
   - Uso: LatÃªncia do processamento interno

3. **`content_items_returned_total{content_type}`**
   - Tipo: Counter
   - Labels: movies/series/live/all
   - Uso: DistribuiÃ§Ã£o de tipos de conteÃºdo retornados

**Endpoint de MÃ©tricas**: `http://localhost:9101/metrics`

#### Service B (Metadados)

**Biblioteca**: `prometheus_client` (Python)

**Arquivo**: `services/b_py/server.py`

**MÃ©tricas**:

1. **`grpc_server_requests_total{method, status}`**
   - Tipo: Counter
   - Labels: StreamMetadata, sucesso/erro

2. **`grpc_server_request_duration_seconds{method}`**
   - Tipo: Histogram
   - Uso: Tempo total de streaming

3. **`grpc_server_stream_items_total{method}`**
   - Tipo: Counter
   - Uso: Total de itens transmitidos via stream

**Endpoint de MÃ©tricas**: `http://localhost:9102/metrics`

### ServiceMonitors (IntegraÃ§Ã£o com Prometheus)

**Arquivo**: `k8s/monitoring/servicemonitor-p.yaml`

```yaml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: service-p-monitor
  namespace: pspd
spec:
  selector:
    matchLabels:
      app: p
  endpoints:
  - port: http
    path: /metrics
    interval: 15s
```

**VerificaÃ§Ã£o**:
```bash
# ServiceMonitors criados
kubectl get servicemonitor -n pspd
# NAME                AGE
# service-a-monitor   5m
# service-b-monitor   5m
# service-p-monitor   5m

# Verificar targets no Prometheus
# â†’ http://localhost:9090/targets
# Procurar: serviceMonitor/pspd/service-p-monitor/0 (UP)
```

### Queries PromQL para AnÃ¡lise

#### Taxa de RequisiÃ§Ãµes HTTP

```promql
# Taxa de requisiÃ§Ãµes por segundo (total)
rate(http_requests_total{container="p"}[1m])

# Taxa por endpoint
rate(http_requests_total{container="p", route="/api/content"}[1m])

# Taxa por cÃ³digo de status
sum by (status_code) (rate(http_requests_total{container="p"}[1m]))
```

#### LatÃªncia

```promql
# LatÃªncia P50 do Gateway P
histogram_quantile(0.50, 
  rate(http_request_duration_seconds_bucket{container="p"}[1m])
)

# LatÃªncia P95 por endpoint
histogram_quantile(0.95, 
  sum by (route, le) (
    rate(http_request_duration_seconds_bucket{container="p"}[1m])
  )
)

# LatÃªncia P99
histogram_quantile(0.99, 
  rate(http_request_duration_seconds_bucket{container="p"}[1m])
)
```

#### Taxa de Erro

```promql
# Taxa de erro HTTP (5xx)
sum(rate(http_requests_total{container="p", status_code=~"5.."}[1m])) / 
sum(rate(http_requests_total{container="p"}[1m]))

# Erros gRPC do Service A
rate(grpc_server_requests_total{container="a", status="error"}[1m])
```

#### Chamadas gRPC

```promql
# Taxa de chamadas Pâ†’A
rate(grpc_client_requests_total{container="p", service="ServiceA"}[1m])

# Taxa de chamadas Pâ†’B
rate(grpc_client_requests_total{container="p", service="ServiceB"}[1m])

# LatÃªncia gRPC Pâ†’A
histogram_quantile(0.95,
  rate(grpc_client_request_duration_seconds_bucket{
    container="p", service="ServiceA"
  }[1m])
)
```

#### AnÃ¡lise de ConteÃºdo

```promql
# DistribuiÃ§Ã£o de tipos de conteÃºdo retornados
sum by (content_type) (
  rate(content_items_returned_total{container="a"}[5m])
)

# Total de itens transmitidos via stream
rate(grpc_server_stream_items_total{container="b"}[1m])
```

#### Autoscaling (HPA)

```promql
# CPU atual dos pods
sum(rate(container_cpu_usage_seconds_total{
  namespace="pspd", pod=~"p-.*"
}[1m])) by (pod)

# NÃºmero de rÃ©plicas ao longo do tempo
count(kube_pod_info{namespace="pspd", pod=~"p-.*"})
```

### Dashboard Grafana

**Arquivo**: `docs/grafana-dashboard.json`

**PainÃ©is IncluÃ­dos**:

1. **Overview**
   - Taxa de requisiÃ§Ãµes HTTP (total)
   - LatÃªncia P50/P95/P99
   - Taxa de erro
   - NÃºmero de rÃ©plicas (HPA)

2. **HTTP Endpoints**
   - LatÃªncia por rota (`/api/content`, `/api/metadata`, `/api/browse`)
   - Throughput por rota
   - Taxa de sucesso/erro por rota

3. **gRPC Communication**
   - Taxa de chamadas Pâ†’A e Pâ†’B
   - LatÃªncia das chamadas gRPC
   - Taxa de erro gRPC

4. **Service A Details**
   - Taxa de requisiÃ§Ãµes recebidas
   - LatÃªncia interna
   - DistribuiÃ§Ã£o de tipos de conteÃºdo

5. **Service B Details**
   - Taxa de requisiÃ§Ãµes streaming
   - Total de itens transmitidos
   - LatÃªncia de streaming

6. **Resource Usage**
   - CPU por pod
   - MemÃ³ria por pod
   - HPA scaling events

**ImportaÃ§Ã£o**:
```bash
# Via UI Grafana:
# â†’ Dashboards â†’ Import â†’ Upload JSON file
# Ou copiar conteÃºdo de docs/grafana-dashboard.json
```

---

## ğŸ¯ Resumo de Atendimento

| Requisito | Status | EvidÃªncia |
|-----------|--------|-----------|
| **AplicaÃ§Ã£o microserviÃ§os gRPC (Pâ†’A,B)** | âœ… Completo | `gateway_p_node/`, `services/a_py/`, `services/b_py/` |
| **Frontend funcional** | âœ… Completo | https://streaming-app-design.vercel.app/ |
| **Cluster K8s multi-node (1+2)** | âœ… Completo | `minikube start --nodes 3` |
| **Prometheus instalado** | âœ… Completo | Helm chart kube-prometheus-stack |
| **Grafana com dashboards** | âœ… Completo | `docs/grafana-dashboard.json` |
| **HPA configurado** | âœ… Completo | `k8s/monitoring/hpa.yaml` |
| **Ferramenta de teste de carga** | âœ… Completo | k6 (https://k6.io/) |
| **CenÃ¡rio base documentado** | âœ… Completo | `test/scenario_1/`, `k8s/scenarios/scenario1-base/` |
| **MÃºltiplos cenÃ¡rios (5 variaÃ§Ãµes)** | âœ… Completo | `test/scenario_{1-5}/` |
| **Testes de carga (baseline/ramp/spike/soak)** | âœ… Completo | `load/*.js` |
| **MÃ©tricas customizadas** | âœ… Completo | 12 mÃ©tricas implementadas |
| **ServiceMonitors** | âœ… Completo | `k8s/monitoring/servicemonitor-*.yaml` |
| **Queries PromQL** | âœ… Completo | `docs/METRICAS_PROMETHEUS.md` |
| **ComparaÃ§Ã£o de cenÃ¡rios** | âœ… Completo | `scripts/run_scenario_comparison.sh` |
| **GrÃ¡ficos de anÃ¡lise** | âœ… Completo | `test_results/scenario-comparison/*.png` |
| **DocumentaÃ§Ã£o completa** | âœ… Completo | `README.md`, `docs/*.md` |

---

## ğŸ“Š Resultados Esperados

ApÃ³s executar todos os testes, o projeto demonstrarÃ¡:

1. **Performance Baseline**:
   - LatÃªncia P95: ~200-500ms
   - Throughput: ~100-300 req/s

2. **Autoscaling Funcional**:
   - HPA criando rÃ©plicas quando CPU > 70%
   - LatÃªncia estÃ¡vel durante scaling

3. **ComparaÃ§Ã£o de CenÃ¡rios**:
   - CenÃ¡rio 2 (warm start): -30% latÃªncia inicial
   - CenÃ¡rio 3 (anti-affinity): +10% resiliÃªncia
   - CenÃ¡rio 4 (recursos limitados): +50% rÃ©plicas criadas
   - CenÃ¡rio 5 (sem HPA): DegradaÃ§Ã£o durante picos

4. **Observabilidade**:
   - Todas as mÃ©tricas visÃ­veis no Prometheus
   - Dashboards Grafana funcionais
   - CorrelaÃ§Ã£o entre eventos (HPA scale â†” latÃªncia)

---

## ğŸ“š DocumentaÃ§Ã£o de ReferÃªncia

- **Kubernetes Autoscaling**: https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/
- **Prometheus Operator**: https://prometheus-operator.dev/
- **gRPC Basics**: https://grpc.io/docs/what-is-grpc/introduction/
- **k6 Documentation**: https://k6.io/docs/
- **Protocol Buffers**: https://protobuf.dev/
