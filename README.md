# Projeto Final PSPD - Monitoramento e Observabilidade em Kubernetes

> Projeto de pesquisa focado em monitoramento e observabilidade de aplicaÃ§Ãµes baseadas em microserviÃ§os em clusters Kubernetes multi-node, com Prometheus, Grafana e Ãªnfase em mÃ©tricas de desempenho.

## ğŸ“‹ Ãndice

- [Arquitetura](#-arquitetura)
- [Setup Multi-Node](#-setup-multi-node-novo)
- [Quick Start](#-quick-start)
- [Sistema de Checkpoints](#-sistema-de-checkpoints-novo)
- [Como Executar](#-como-executar)
- [Testes de Carga](#-testes-de-carga)
- [Monitoramento](#-monitoramento)
- [Estrutura do Projeto](#-estrutura-do-projeto)
- [Troubleshooting](#-troubleshooting)

---

## ğŸ—ï¸ Arquitetura

### Cluster Kubernetes Multi-Node

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Cluster K8s (1 Master + 2 Workers)                     â”‚
â”‚                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Namespace: pspd                                   â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚ â”‚
â”‚  â”‚  â”‚ Gateway P â”‚  â”‚ Service A â”‚  â”‚ Service B â”‚     â”‚ â”‚
â”‚  â”‚  â”‚  (Node.js)â”‚  â”‚  (Python) â”‚  â”‚  (Python) â”‚     â”‚ â”‚
â”‚  â”‚  â”‚  :8080    â”‚  â”‚  :9101    â”‚  â”‚  :9102    â”‚     â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜     â”‚ â”‚
â”‚  â”‚        â”‚ gRPC         â”‚                â”‚          â”‚ â”‚
â”‚  â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Namespace: monitoring                             â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚ â”‚
â”‚  â”‚  â”‚  Prometheus  â”‚  â”‚   Grafana    â”‚               â”‚ â”‚
â”‚  â”‚  â”‚  :9090       â”‚  â”‚   :3000      â”‚               â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚ â”‚
â”‚  â”‚         â”‚ scrape                                   â”‚ â”‚
â”‚  â”‚         â””â”€â”€â”€â”€â”€â–º ServiceMonitors                    â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### MicroserviÃ§os gRPC
```
Cliente HTTP â†’ Gateway P (Node.js + Express)
                    â†“ gRPC
              â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”
              â†“           â†“
        Service A    Service B
        (Python)     (Python)
```

- **Gateway P**: WEB API que recebe requisiÃ§Ãµes HTTP e distribui via gRPC
- **Service A**: MicroserviÃ§o gRPC com mensagens personalizadas
- **Service B**: MicroserviÃ§o gRPC com streaming de nÃºmeros

### InstrumentaÃ§Ã£o Prometheus

Todos os serviÃ§os expÃµem mÃ©tricas em `/metrics`:

**Gateway P (porta 8080)**:
- `http_requests_total`, `http_request_duration_seconds`
- `grpc_client_requests_total`, `grpc_client_request_duration_seconds`

**Services A/B (portas 9101/9102)**:
- `grpc_server_requests_total`, `grpc_server_request_duration_seconds`
- `grpc_server_stream_items_total` (apenas B)

---

## ğŸš€ Setup Multi-Node (NOVO)

### OpÃ§Ã£o 1: Setup Completo Automatizado

```bash
# Criar cluster multi-node + Prometheus + Grafana (5-10 min)
./scripts/setup_multinode_cluster.sh

# Deploy das aplicaÃ§Ãµes
./scripts/deploy.sh setup

# Configurar ServiceMonitors
./scripts/deploy.sh monitoring
```

âœ… **Resultado**: Cluster com 1 master + 2 workers + Prometheus + Grafana instalados

### OpÃ§Ã£o 2: Setup Passo a Passo

Ver documentaÃ§Ã£o detalhada em: **[GUIA_MULTINODE.md](docs/GUIA_MULTINODE.md)**

---

## ğŸš€ Quick Start

### ExecuÃ§Ã£o Completa Automatizada âš¡

```bash
# Uma linha - setup completo!
./RUN_COMPLETE.sh

# âœ… Cria cluster multi-node (1 master + 2 workers)
# âœ… Instala Prometheus + Grafana
# âœ… Deploy das aplicaÃ§Ãµes
# âœ… Configura ServiceMonitors
# âœ… Executa testes de carga
# âœ… Gera anÃ¡lises e grÃ¡ficos
# â±ï¸  Tempo total: 15-20 minutos
```

### ğŸ”„ Sistema de Checkpoints (NOVO!)

Se algo der erro, **nÃ£o precisa recomeÃ§ar do zero**!

```bash
./RUN_COMPLETE.sh

# Se der erro, execute novamente:
./RUN_COMPLETE.sh

# ğŸ“ Checkpoint encontrado! Ãšltima etapa concluÃ­da: 2/5
# 
# OpÃ§Ãµes:
#   1. âœ… Continuar de onde parou (Etapa 3)
#   2. ğŸ”„ RecomeÃ§ar do zero
#   3. âŒ Cancelar

# Escolha "1" e economize tempo! ğŸš€
```

ğŸ“– **Guia completo**: [COMO_CONTINUAR.md](docs/COMO_CONTINUAR.md)

### PrÃ©-requisitos
```bash
# Verificar ferramentas instaladas
minikube version
kubectl version --client
docker --version
k6 version
python3 --version
```

### Setup Manual (se preferir controle total)

```bash
# 1. Criar cluster multi-node
./scripts/setup_multinode_cluster.sh

# 2. Deploy aplicaÃ§Ãµes
./scripts/deploy.sh setup

# 3. Configurar monitoramento
./scripts/deploy.sh monitoring

# 4. Executar testes
./scripts/run_all_tests.sh all
```

---

## ğŸ’» Como Executar

### ExecuÃ§Ã£o AutomÃ¡tica (Recomendado)

```bash
# Terminal 1: Port-forward monitorado (auto-restart)
./scripts/stable_port_forward.sh

# Terminal 2: Executar todos os testes
BASE_URL=http://localhost:8080 ./scripts/run_all_tests.sh

# Terminal 3 (opcional): Monitorar em tempo real
./scripts/monitor.sh
```

### ExecuÃ§Ã£o Manual

```bash
# Terminal 1: Port-forward simples
kubectl port-forward -n pspd svc/p-svc 8080:80

# Terminal 2: Teste individual
BASE_URL=http://localhost:8080 k6 run load/baseline.js
BASE_URL=http://localhost:8080 k6 run load/ramp.js
BASE_URL=http://localhost:8080 k6 run load/spike.js

# Para teste longo (11 min), use port-forward monitorado
```

### Gerar AnÃ¡lise

```bash
# ApÃ³s executar testes
python3 scripts/analyze_results.py

# Resultados em:
# - results/plots/*.png (6 grÃ¡ficos comparativos)
# - results/plots/SUMMARY_REPORT.txt
```

---

## ğŸ“Š Testes de Carga

### CenÃ¡rios K6 (Testes de Carga)

| Teste | DuraÃ§Ã£o | Carga | Objetivo |
|-------|---------|-------|----------|
| **baseline.js** | 2 min | 10 VUs constantes | Linha de base de performance |
| **ramp.js** | 4 min | 10â†’150 VUs gradual | Testar autoscaling (HPA) |
| **spike.js** | 1.5 min | 10â†’200 VUs sÃºbito | ResiliÃªncia a picos (~33% erro esperado) |
| **soak.js** | 11 min | 50 VUs sustentado | Estabilidade long-term |
| **stress.js** | 1.5 min | 10â†’200 VUs | Encontrar limite (PODE ter erros) |

### CenÃ¡rios de ConfiguraÃ§Ã£o K8s (AnÃ¡lise Comparativa)

**5 cenÃ¡rios distintos** para avaliar impacto de configuraÃ§Ãµes no desempenho:

| CenÃ¡rio | DescriÃ§Ã£o | Foco |
|---------|-----------|------|
| **1. Base** | HPA enabled, 1 replica inicial | Autoscaling padrÃ£o |
| **2. Replicas** | 2 replicas iniciais | Warm start |
| **3. Distribution** | Anti-affinity forÃ§ada | Alta disponibilidade |
| **4. Resources** | CPU/Memory -50% | Economia de recursos |
| **5. No HPA** | RÃ©plicas fixas (3/5) | Sem autoscaling |

**Comandos**:

```bash
# Executar todos os 5 cenÃ¡rios (2-3 horas)
./scripts/run_scenario_comparison.sh --all

# Menu interativo para escolher cenÃ¡rio especÃ­fico
./scripts/run_scenario_comparison.sh

# Gerar apenas grÃ¡ficos comparativos (dados jÃ¡ existentes)
./scripts/run_scenario_comparison.sh --compare
```

**ğŸ“ˆ SaÃ­da**: 6 grÃ¡ficos comparativos + relatÃ³rios (ver `scenario-comparison/README.md`)

**DocumentaÃ§Ã£o completa**: `k8s/scenarios/README.md`

---

### MÃ©tricas Coletadas

**Performance**:
- LatÃªncia (p50/p90/p95/p99)
- Throughput (req/s)
- Taxa de sucesso/falha

**Infraestrutura**:
- CPU/MemÃ³ria por pod
- NÃºmero de rÃ©plicas (HPA)
- Eventos de scaling

**Exemplo de Resultados**:
```
Baseline: ~150 req/s, p95 < 25ms, 100% sucesso
Ramp: HPA escala 1â†’3 rÃ©plicas, p95 < 500ms, 100% sucesso
Spike: Pico de 200 VUs, p95 < 2s, taxa erro < 10%, recuperaÃ§Ã£o rÃ¡pida
Soak: EstÃ¡vel por 11 min, p95 < 10ms, 100% sucesso
Stress (opcional): 200 VUs, identifica limite mÃ¡ximo (pode ter erros)
```

---

## ğŸ“Š Monitoramento

### Acessar Grafana

```bash
# OpÃ§Ã£o 1: Port-forward
./scripts/deploy.sh grafana
# Acesse: http://localhost:3000
# User: admin | Password: admin

# OpÃ§Ã£o 2: NodePort (mais estÃ¡vel)
MINIKUBE_IP=$(minikube ip -p pspd-cluster)
GRAFANA_PORT=$(kubectl get svc -n monitoring prometheus-grafana -o jsonpath='{.spec.ports[0].nodePort}')
echo "http://$MINIKUBE_IP:$GRAFANA_PORT"
```

### Importar Dashboard

1. Acesse Grafana
2. VÃ¡ em **+** â†’ **Import** â†’ **Upload JSON file**
3. Selecione `k8s/monitoring/grafana-dashboard.json`
4. Dashboard inclui:
   - ğŸ“ˆ HTTP Request Rate
   - â±ï¸ Request Duration (p95, p99)
   - ğŸ”¢ Pod Replicas (HPA)
   - ğŸ’» CPU/Memory Usage
   - âŒ Error Rate

### Acessar Prometheus

```bash
# Port-forward
./scripts/deploy.sh prometheus
# Acesse: http://localhost:9090

# Queries Ãºteis:
# rate(http_requests_total{namespace="pspd"}[1m])
# histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[1m]))
```

### Verificar ServiceMonitors

```bash
# Listar ServiceMonitors
kubectl get servicemonitor -n pspd

# Verificar targets no Prometheus
# Acesse: http://localhost:9090/targets
# Deve mostrar 3 targets UP:
# - pspd/service-a-monitor
# - pspd/service-b-monitor
# - pspd/gateway-p-monitor
```

---

## ğŸ“ Estrutura do Projeto

```
atividade-final-pspd/
â”œâ”€â”€ gateway_p_node/          # Gateway HTTPâ†’gRPC (Node.js + prom-client)
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ a_py/                # Service A (Python + prometheus_client)
â”‚   â””â”€â”€ b_py/                # Service B (Python + prometheus_client)
â”œâ”€â”€ k8s/
â”‚   â”œâ”€â”€ *.yaml               # Deployments, Services
â”‚   â”œâ”€â”€ p-nodeport.yaml      # NodePort para acesso estÃ¡vel
â”‚   â””â”€â”€ monitoring/
â”‚       â”œâ”€â”€ hpa.yaml         # Autoscaling (CPU 70%, Memory 80%)
â”‚       â”œâ”€â”€ servicemonitor-*.yaml      # Prometheus ServiceMonitors
â”‚       â””â”€â”€ grafana-dashboard.json     # Dashboard customizado
â”œâ”€â”€ load/                    # 4 cenÃ¡rios k6
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ setup_multinode_cluster.sh  # Criar cluster 1+2 nodes
â”‚   â”œâ”€â”€ deploy.sh            # Deploy K8s + monitoramento
â”‚   â”œâ”€â”€ run_all_tests.sh     # Suite completa + anÃ¡lise
â”‚   â””â”€â”€ analyze_results.py   # Gerar grÃ¡ficos
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ baseline/            # Resultados baseline
â”‚   â”œâ”€â”€ ramp/                # Resultados ramp
â”‚   â”œâ”€â”€ spike/               # Resultados spike
â”‚   â”œâ”€â”€ soak/                # Resultados soak
â”‚   â””â”€â”€ plots/               # GrÃ¡ficos + relatÃ³rio
â”œâ”€â”€ GUIA_MULTINODE.md        # Guia detalhado multi-node
â””â”€â”€ README.md                # Este arquivo
```

---

## ğŸ”§ Troubleshooting

### Cluster multi-node nÃ£o inicia

**SoluÃ§Ã£o**:
```bash
# Aumentar recursos
minikube delete -p pspd-cluster
minikube start -p pspd-cluster --nodes 3 --cpus 4 --memory 8192
```

### Prometheus nÃ£o coleta mÃ©tricas

**SoluÃ§Ã£o**:
```bash
# Verificar ServiceMonitors
kubectl get servicemonitor -n pspd

# Recriar
./scripts/deploy.sh monitoring

# Ver logs
kubectl logs -n monitoring prometheus-kube-prometheus-prometheus-0
```

### Port-forward cai durante testes

**Problema**: `connection reset by peer` em testes longos

**SoluÃ§Ã£o**:
```bash
# Usar port-forward monitorado (reinicia automaticamente)
./scripts/deploy.sh port-forward
```

### HPA mostra `<unknown>` em TARGETS

**Normal** logo apÃ³s deploy. Aguardar 30-60s para metrics-server coletar dados.

```bash
# ForÃ§ar coleta
kubectl top pods -n pspd
kubectl get hpa -n pspd  # Verificar novamente
```

### Pods nÃ£o iniciam

```bash
# Ver logs
kubectl logs -n pspd <pod-name>

# Ver eventos
kubectl describe pod -n pspd <pod-name>

# Rebuild e redeploy
./scripts/build_images.sh
kubectl rollout restart deployment -n pspd p-deploy a-deploy b-deploy
```

### k6 nÃ£o encontrado

```bash
# Ubuntu/Debian
sudo gpg -k
sudo gpg --no-default-keyring --keyring /usr/share/keyrings/k6-archive-keyring.gpg \
  --keyserver hkp://keyserver.ubuntu.com:80 \
  --recv-keys C5AD17C747E3415A3642D57D77C6C491D6AC1D69
echo "deb [signed-by=/usr/share/keyrings/k6-archive-keyring.gpg] https://dl.k6.io/deb stable main" \
  | sudo tee /etc/apt/sources.list.d/k6.list
sudo apt-get update
sudo apt-get install k6
```

### Verificar conectividade

```bash
# Executar guia de diagnÃ³stico
./COMO_EXECUTAR.sh

# Deve mostrar:
# âœ… Gateway respondendo
# âœ… MÃ©tricas Prometheus expostas
```

---

## ğŸ¯ Requisitos AcadÃªmicos Atendidos

### âœ… Cluster Multi-Node Implementado

**Requisito**: "Cluster composto por um nÃ³ mestre (plano de controle) e pelo menos dois nÃ³s escravos (worker nodes)"

**ImplementaÃ§Ã£o**:
```bash
./scripts/setup_multinode_cluster.sh
# Cria: 1 master (pspd-cluster) + 2 workers (pspd-cluster-m02, m03)
```

**VerificaÃ§Ã£o**:
```bash
kubectl get nodes
# NAME               STATUS   ROLES           AGE
# pspd-cluster       Ready    control-plane   10m
# pspd-cluster-m02   Ready    worker          9m
# pspd-cluster-m03   Ready    worker          8m
```

### âœ… Prometheus Instalado no K8s

**Requisito**: "Estudar e instalar, no K8S, o Prometheus"

**ImplementaÃ§Ã£o**:
- kube-prometheus-stack via Helm
- Inclui: Prometheus Operator + Alertmanager
- ServiceMonitors configurados para scraping automÃ¡tico

**VerificaÃ§Ã£o**:
```bash
kubectl get pods -n monitoring | grep prometheus
# prometheus-kube-prometheus-prometheus-0   2/2   Running

kubectl get servicemonitor -n pspd
# gateway-p-monitor, service-a-monitor, service-b-monitor
```

**Acesso**:
```bash
./scripts/deploy.sh prometheus
# http://localhost:9090
```

### âœ… Interface Web de Monitoramento

**Requisito**: "Interface web de monitoramento do cluster"

**ImplementaÃ§Ã£o**:
- Grafana instalado com kube-prometheus-stack
- Dashboard customizado em `k8s/monitoring/grafana-dashboard.json`
- MÃ©tricas: Request Rate, Duration, Replicas, CPU, Memory, Error Rate

**VerificaÃ§Ã£o**:
```bash
kubectl get pods -n monitoring | grep grafana
# prometheus-grafana-xxx   3/3   Running
```

**Acesso**:
```bash
./scripts/deploy.sh grafana
# http://localhost:3000
# User: admin | Password: admin
```

**Dashboard inclui**:
- ğŸ“ˆ HTTP Request Rate por serviÃ§o
- â±ï¸ Request Duration (p95, p99)
- ğŸ”¢ Pod Replicas (HPA)
- ğŸ’» CPU Usage por pod
- ğŸ’¾ Memory Usage por pod
- âŒ Error Rate

### âœ… AplicaÃ§Ã£o Instrumentada

- âœ… Gateway P: Express + prom-client
- âœ… Service A: Python + prometheus_client
- âœ… Service B: Python + prometheus_client
- âœ… MÃ©tricas HTTP e gRPC
- âœ… Histogramas de latÃªncia

### âœ… Testes de Carga e AnÃ¡lise

- âœ… 4 cenÃ¡rios k6 (baseline, ramp, spike, soak)
- âœ… AnÃ¡lise comparativa automatizada
- âœ… 6 grÃ¡ficos gerados
- âœ… Captura de mÃ©tricas K8s (HPA, CPU, Memory)

---

## ğŸ“ˆ AnÃ¡lise de Resultados

### Queries PromQL Ãšteis

```promql
# Throughput
rate(http_requests_total[1m])

# LatÃªncia p95
histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[1m]))

# Taxa de erro
rate(http_requests_total{status_code=~"5.."}[1m]) / rate(http_requests_total[1m])

# CPU por pod
rate(container_cpu_usage_seconds_total{namespace="pspd"}[1m])
```

### GrÃ¡ficos Gerados

ApÃ³s `python3 scripts/analyze_results.py`:

1. `01_latency_comparison.png` - LatÃªncias mÃ©dias/p90/p95
2. `02_throughput_comparison.png` - Req/s + total de requisiÃ§Ãµes
3. `03_success_rate.png` - Taxa de sucesso vs falha
4. `04_hpa_scaling.png` - EvoluÃ§Ã£o de rÃ©plicas (P, A, B)
5. `05_resource_usage.png` - CPU e memÃ³ria
6. `06_latency_percentiles.png` - DistribuiÃ§Ã£o completa

---

## ğŸ¯ PrÃ³ximos Passos (Opcional)

### Melhorias Futuras

1. **Alertas Prometheus**
   - Configurar AlertManager
   - Regras de alerta para latÃªncia alta, erro rate, etc.

2. **Testes Adicionais**
   - Variar rÃ©plicas mÃ­nimas/mÃ¡ximas do HPA
   - Testar distribuiÃ§Ã£o de carga nos 2 workers
   - CenÃ¡rios com falhas de nÃ³s

3. **Dashboards Adicionais**
   - Dashboard de infraestrutura K8s
   - Dashboard de rede (ingress/egress)
   - Dashboard de custos (resource quotas)

4. **CI/CD**
   - Pipeline GitHub Actions
   - Deploy automatizado
   - Testes automatizados

---

## ğŸ“š ReferÃªncias

- [Prometheus Best Practices](https://prometheus.io/docs/practices/)
- [k6 Load Testing](https://k6.io/docs/)
- [Kubernetes HPA](https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/)
- [gRPC Observability](https://grpc.io/docs/guides/monitoring/)

---

## ğŸ‘¥ Autores

Projeto desenvolvido para a disciplina **PSPD - ProgramaÃ§Ã£o para Sistemas Paralelos e DistribuÃ­dos**.

**RepositÃ³rio**: [github.com/edilbertocantuaria/atividade-final-pspd](https://github.com/edilbertocantuaria/atividade-final-pspd)
