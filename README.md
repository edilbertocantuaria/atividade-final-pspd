# Plataforma de Streaming - Monitoramento K8s

AplicaÃ§Ã£o de streaming baseada em microsserviÃ§os gRPC com monitoramento Prometheus/Grafana em cluster Kubernetes multi-node.

**Frontend**: https://streaming-app-design.vercel.app/

---

## âš¡ Arquitetura da AplicaÃ§Ã£o

```
Frontend (Next.js) â†’ Gateway P (Node.js/Express)
                          â†“ gRPC
                     â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
                     â†“         â†“
              Service A    Service B
              (CatÃ¡logo)   (Metadados/RecomendaÃ§Ãµes)
              Python       Python Streaming
```

### MÃ³dulos da AplicaÃ§Ã£o

**Gateway P (Web API)**:
- Recebe requisiÃ§Ãµes HTTP do frontend Next.js
- ExpÃµe API REST: `/api/content`, `/api/metadata/:id`, `/api/browse`
- Converte HTTP â†’ gRPC para comunicaÃ§Ã£o com microsserviÃ§os
- MÃ©tricas Prometheus em `/metrics`

**Service A (CatÃ¡logo de ConteÃºdo)**:
- Fornece catÃ¡logo de filmes, sÃ©ries e canais ao vivo
- RPC unÃ¡ria: `GetContent(type, limit, genre) â†’ ContentResponse`
- Filtros: tipo de conteÃºdo, gÃªnero, limite de resultados
- Retorna: 12 itens (4 filmes + 4 sÃ©ries + 3 canais + metadados)

**Service B (Metadados e RecomendaÃ§Ãµes)**:
- Fornece metadados detalhados via streaming
- RPC streaming: `StreamMetadata(contentId) â†’ stream<MetadataItem>`
- Retorna: diretor, elenco, similaridade, recomendaÃ§Ãµes
- SimulaÃ§Ã£o de processamento incremental (anÃ¡lise de dados)

---

## ğŸ“Š Endpoints da API

### `/api/content?type=movies&limit=10&genre=AÃ§Ã£o`
Retorna catÃ¡logo filtrado via Service A (gRPC unÃ¡rio)
```json
{
  "items": [
    {
      "id": "m1",
      "title": "A Jornada Infinita",
      "type": "movie",
      "genres": ["FicÃ§Ã£o CientÃ­fica", "Aventura"],
      "rating": 8.7
    }
  ],
  "total": 4,
  "source": "ServiceA"
}
```

### `/api/metadata/m1?userId=user123`
Retorna metadados via Service B (gRPC streaming)
```json
{
  "contentId": "m1",
  "metadata": [
    {"key": "director", "value": "James Cameron", "relevanceScore": 0.95},
    {"key": "similar", "value": "Interestelar", "relevanceScore": 0.85}
  ],
  "source": "ServiceB"
}
```

### `/api/browse?type=all&limit=10`
**Endpoint combinado**: catÃ¡logo (A) + metadados do destaque (B)
```json
{
  "catalog": [...],
  "total": 12,
  "featuredMetadata": [...],
  "processingTime": "45.23ms"
}
```

---

## âš¡ Comandos Essenciais

### Setup Inicial (uma vez)
```bash
# 1. Criar cluster Kubernetes
minikube start --nodes 3 --cpus 4 --memory 8192
minikube addons enable metrics-server ingress

# 2. Build das imagens
eval $(minikube docker-env)
docker build -t a-py:latest ./services/a_py
docker build -t b-py:latest ./services/b_py
docker build -t p-node:latest ./gateway_p_node

# 3. Deploy aplicaÃ§Ã£o
kubectl apply -f k8s/
kubectl apply -f k8s/monitoring/  # Opcional: apenas se tiver Prometheus instalado
```

### Executar Testes

**OpÃ§Ã£o 1: Testes RÃ¡pidos (cenÃ¡rio Ãºnico - ~20 min)**
```bash
# Executar 4 testes k6 no cenÃ¡rio atual
./scripts/run_all_tests.sh all

# Ou testes individuais
./scripts/run_all_tests.sh baseline
./scripts/run_all_tests.sh spike
./scripts/run_all_tests.sh monitor  # Monitor em tempo real
```

**OpÃ§Ã£o 2: AnÃ¡lise Comparativa Completa (5 cenÃ¡rios - 2-3h)**
```bash
# 1. Executar todos os 5 cenÃ¡rios (5 Ã— 4 testes = 20 execuÃ§Ãµes)
./test/run_all_scenarios.sh

# 2. Gerar comparaÃ§Ã£o entre cenÃ¡rios
./scripts/run_scenario_comparison.sh --all
```

### Visualizar MÃ©tricas e Dashboards

ğŸ“Š **[Guia Completo: VISUALIZAR_METRICAS.md](./VISUALIZAR_METRICAS.md)**

**Acesso rÃ¡pido**:
```bash
# Prometheus
kubectl port-forward -n monitoring svc/prometheus-kube-prometheus-prometheus 9090:9090
# â†’ http://localhost:9090

# Grafana
kubectl port-forward -n monitoring svc/prometheus-grafana 3000:80
# â†’ http://localhost:3000
# User: admin | Password: (ver VISUALIZAR_METRICAS.md)
```

---

## ğŸ“Š Arquitetura

```
HTTP Request â†’ Gateway P (Node.js)
                   â†“ gRPC
              â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
              â†“         â†“
         Service A  Service B
         (Python)   (Python streaming)
```

**Cluster K8s**: 1 master + 2 workers  
**Monitoramento**: Prometheus + Grafana  
**Autoscaling**: HPA configurado (CPU 70%, 1-10 replicas)

---

## ğŸ§ª Testes de Carga (k6)

Simulam trÃ¡fego de usuÃ¡rios acessando a plataforma de streaming:

| Teste | DuraÃ§Ã£o | VUs | CenÃ¡rio Simulado |
|-------|---------|-----|------------------|
| **baseline** | 2min | 10 | Uso normal (navegaÃ§Ã£o por catÃ¡logo) |
| **ramp** | 4.5min | 10â†’150 | HorÃ¡rio nobre (gradual) - testa HPA |
| **spike** | 1.5min | 10â†’200â†’10 | LanÃ§amento de sÃ©rie viral |
| **soak** | 11.5min | 50 | Maratona de fim de semana |

### PadrÃ£o de RequisiÃ§Ãµes
Cada VU simula um usuÃ¡rio real:
1. Lista catÃ¡logo completo: `GET /api/content?type=all`
2. Filtra filmes: `GET /api/content?type=movies&limit=10`
3. Busca metadados de um filme: `GET /api/metadata/m1`
4. Consulta combinada: `GET /api/browse?type=series`

### MÃ©tricas Coletadas
- LatÃªncia (p50, p95, p99)
- Throughput (req/s)
- Taxa de sucesso/erro
- Scaling HPA (rÃ©plicas)
- CPU/MemÃ³ria por pod

### Resultados
```
results/
â”œâ”€â”€ baseline/output.txt
â”œâ”€â”€ ramp/output.txt
â”œâ”€â”€ spike/output.txt
â”œâ”€â”€ soak/output.txt
â””â”€â”€ plots/
    â”œâ”€â”€ 01_latency_comparison.png
    â”œâ”€â”€ 02_throughput_comparison.png
    â”œâ”€â”€ 03_success_rate.png
    â”œâ”€â”€ 04_hpa_scaling.png
    â”œâ”€â”€ 05_resource_usage.png
    â””â”€â”€ 06_latency_percentiles.png
```

---

## ğŸ¯ CenÃ¡rios de Teste

5 configuraÃ§Ãµes diferentes para anÃ¡lise comparativa:

| # | Nome | DescriÃ§Ã£o | Foco |
|---|------|-----------|------|
| 1 | **base** | HPA padrÃ£o, 1 rÃ©plica inicial | Baseline |
| 2 | **replicas** | 2 rÃ©plicas iniciais | Warm start |
| 3 | **distribution** | Anti-affinity forÃ§ada | Alta disponibilidade |
| 4 | **resources** | CPU/Mem -50% | Recursos limitados |
| 5 | **no-hpa** | RÃ©plicas fixas (3/5) | Sem autoscaling |

### Executar CenÃ¡rios
```bash
# Todos os cenÃ¡rios (2-3 horas)
./scripts/run_scenario_comparison.sh --all

# Apenas gerar grÃ¡ficos comparativos
./scripts/run_scenario_comparison.sh --compare

# Menu interativo (escolher 1 cenÃ¡rio)
./scripts/run_scenario_comparison.sh
```

### SaÃ­da Esperada
```
scenario-comparison/
â”œâ”€â”€ 01_scenario_latency_comparison.png
â”œâ”€â”€ 02_scenario_throughput_comparison.png
â”œâ”€â”€ 03_scenario_hpa_scaling.png
â”œâ”€â”€ 04_scenario_success_rate.png
â”œâ”€â”€ 05_scenario_cost_analysis.png
â”œâ”€â”€ 06_scenario_performance_radar.png
â””â”€â”€ SCENARIO_COMPARISON_REPORT.txt
```

---

## ğŸ“ˆ MÃ©tricas Prometheus

### MÃ©tricas Customizadas

**Gateway P (8080/metrics)**:
- `http_requests_total{method,route,status_code}`
- `http_request_duration_seconds{method,route,status_code}`
- `grpc_client_requests_total{service,method,status}`
- `grpc_client_request_duration_seconds{service,method,status}`

**Service A (9101/metrics)**:
- `grpc_server_requests_total{method,status}`
- `grpc_server_request_duration_seconds{method}`

**Service B (9102/metrics)**:
- `grpc_server_requests_total{method,status}`
- `grpc_server_request_duration_seconds{method}`
- `grpc_server_stream_items_total{method}`

### Queries PromQL Ãšteis
```promql
# Taxa de requisiÃ§Ãµes HTTP
rate(http_requests_total{app="p"}[1m])

# LatÃªncia P95 do Gateway
histogram_quantile(0.95, rate(http_request_duration_seconds_bucket{app="p"}[1m]))

# Taxa de erros
rate(http_requests_total{app="p",status_code=~"5.."}[1m])

# Chamadas gRPC do Gateway
rate(grpc_client_requests_total{app="p"}[1m])

# LatÃªncia do Service A
histogram_quantile(0.95, rate(grpc_server_request_duration_seconds_bucket{app="a"}[1m]))
```

---

## ğŸ—‚ï¸ Estrutura do Projeto

```
.
â”œâ”€â”€ k8s/                          # Manifests Kubernetes
â”‚   â”œâ”€â”€ a.yaml                    # Deployment + Service A
â”‚   â”œâ”€â”€ b.yaml                    # Deployment + Service B
â”‚   â”œâ”€â”€ p.yaml                    # Deployment + Service Gateway P
â”‚   â”œâ”€â”€ monitoring/               # HPA + ServiceMonitors
â”‚   â””â”€â”€ scenarios/                # 5 cenÃ¡rios de teste
â”‚       â”œâ”€â”€ scenario1-base/
â”‚       â”œâ”€â”€ scenario2-replicas/
â”‚       â”œâ”€â”€ scenario3-distribution/
â”‚       â”œâ”€â”€ scenario4-resources/
â”‚       â””â”€â”€ scenario5-no-hpa/
â”‚
â”œâ”€â”€ services/                     # CÃ³digo dos microserviÃ§os
â”‚   â”œâ”€â”€ a_py/                     # Service A (Python gRPC)
â”‚   â”œâ”€â”€ b_py/                     # Service B (Python gRPC streaming)
â”‚   â””â”€â”€ gateway_p_node/           # Gateway P (Node.js + Express)
â”‚
â”œâ”€â”€ load/                         # Scripts k6
â”‚   â”œâ”€â”€ baseline.js
â”‚   â”œâ”€â”€ ramp.js
â”‚   â”œâ”€â”€ spike.js
â”‚   â””â”€â”€ soak.js
â”‚
â””â”€â”€ scripts/                      # AutomaÃ§Ã£o
    â”œâ”€â”€ run_all_tests.sh
    â”œâ”€â”€ run_scenario_comparison.sh
    â””â”€â”€ analyze_results.py
```

---

## ğŸ”§ Comandos Ãšteis

### Cluster
```bash
# Status do cluster
minikube status
kubectl get nodes

# Ver pods
kubectl get pods -n pspd
kubectl get pods -n monitoring

# Logs
kubectl logs -n pspd -l app=p
kubectl logs -n pspd -l app=a
```

### Testes Manuais
```bash
# Port-forward do Gateway P
kubectl port-forward -n pspd svc/p-svc 8080:80

# Testar endpoints
curl "http://localhost:8080/api/content?type=all&limit=10"
curl "http://localhost:8080/api/metadata/m1?userId=teste"
curl "http://localhost:8080/api/browse?type=series&limit=5"
```

### MÃ©tricas
```bash
# Ver mÃ©tricas do Service A
kubectl port-forward -n pspd svc/a-svc 9101:9101
curl http://localhost:9101/metrics | grep grpc_server

# Verificar targets no Prometheus
# â†’ http://localhost:9090/targets
# Procurar: serviceMonitor/pspd/service-a-monitor/0
```

### Limpeza
```bash
# Deletar namespace
kubectl delete namespace pspd

# Parar cluster
minikube stop

# Deletar cluster
minikube delete
```

---

## ğŸ“š DocumentaÃ§Ã£o Adicional

- **`docs/METRICAS_PROMETHEUS.md`** - Detalhes de todas as mÃ©tricas e queries PromQL
- **`k8s/scenarios/README.md`** - ConfiguraÃ§Ã£o dos 5 cenÃ¡rios de teste
- **`scenario-comparison/README.md`** - InterpretaÃ§Ã£o dos grÃ¡ficos comparativos

---

## ğŸ› Troubleshooting

### Pods nÃ£o iniciam
```bash
kubectl describe pod -n pspd <pod-name>
kubectl logs -n pspd <pod-name>
```

### HPA nÃ£o escala
```bash
kubectl get hpa -n pspd
kubectl describe hpa -n pspd a-hpa
kubectl top pods -n pspd  # Verificar CPU
```

### MÃ©tricas nÃ£o aparecem no Prometheus
```bash
# Verificar ServiceMonitors
kubectl get servicemonitor -n pspd

# Testar endpoint direto
kubectl exec -n pspd <pod-a> -- curl localhost:9101/metrics
```

### Port-forward falha (porta jÃ¡ em uso)
```bash
# Encontrar processo
ps aux | grep port-forward

# Matar processo
pkill -f "port-forward"
```

---

## ğŸ‘¥ Autores

Projeto Final - PSPD 2025.2
