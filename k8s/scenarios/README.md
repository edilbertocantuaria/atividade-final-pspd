# ğŸ¯ CenÃ¡rios de Teste - AnÃ¡lise Comparativa

## VisÃ£o Geral

Esta estrutura implementa 5 cenÃ¡rios distintos para anÃ¡lise comparativa de performance, escalabilidade e custos em Kubernetes, conforme requisito **3.c** da atividade.

## ğŸ“‹ SumÃ¡rio dos CenÃ¡rios

| # | Nome | CaracterÃ­stica Principal | Objetivo |
|---|------|--------------------------|----------|
| 1 | **Base** | HPA ativo, 1 rÃ©plica inicial | Baseline de referÃªncia |
| 2 | **RÃ©plicas** | InÃ­cio com 2 rÃ©plicas | Avaliar warm start vs cold start |
| 3 | **DistribuiÃ§Ã£o** | Anti-affinity, 1 pod/node | Testar HA e latÃªncia inter-node |
| 4 | **Recursos** | Limites reduzidos (50% CPU/Mem) | Stress test com recursos escassos |
| 5 | **Sem HPA** | RÃ©plicas fixas (3-5) | Baseline sem elasticidade |

---

## ğŸ”¬ CenÃ¡rio 1: Base (ReferÃªncia)

**Arquivo**: `scenario1-base/`

### ConfiguraÃ§Ã£o
- RÃ©plicas iniciais: 1 (a, b, p)
- HPA: âœ… Ativo (1-5 para a/b, 1-10 para p)
- CPU target: 70%
- Recursos: 100m/500m CPU, 128Mi/256Mi Mem

### HipÃ³tese
Estabelecer baseline de performance com autoscaling padrÃ£o.

### MÃ©tricas Chave
- LatÃªncia P95 baseline
- Tempo de scale-up
- UtilizaÃ§Ã£o de recursos
- Custo mÃ©dio (pod*min)

---

## ğŸš€ CenÃ¡rio 2: RÃ©plicas Aumentadas

**Arquivo**: `scenario2-replicas/`

### ConfiguraÃ§Ã£o
- RÃ©plicas iniciais: **2** (a, b, p) â¬†ï¸
- HPA: âœ… Ativo (2-5 para a/b, 2-10 para p)
- CPU target: 70%
- Recursos: Mesmos do base

### HipÃ³tese
Iniciar com mais rÃ©plicas reduz latÃªncia inicial (elimina cold start) mas aumenta custo.

### ComparaÃ§Ã£o com CenÃ¡rio 1
| MÃ©trica | CenÃ¡rio 1 | CenÃ¡rio 2 | Esperado |
|---------|-----------|-----------|----------|
| LatÃªncia baseline | ReferÃªncia | Menor | â¬‡ï¸ -20% |
| Throughput inicial | ReferÃªncia | Maior | â¬†ï¸ +100% |
| Cold start | Sim | NÃ£o | âœ… |
| Custo baseline | ReferÃªncia | 2x | â¬†ï¸ +100% |

---

## ğŸŒ CenÃ¡rio 3: DistribuiÃ§Ã£o ForÃ§ada

**Arquivo**: `scenario3-distribution/`

### ConfiguraÃ§Ã£o
- RÃ©plicas iniciais: **3** (a, b, p) â¬†ï¸
- **Pod Anti-Affinity**: 1 pod por node (distribuÃ­do)
- HPA: âœ… Ativo (3-6 para a/b, 3-12 para p)
- CPU target: 70%
- Recursos: Mesmos do base

### HipÃ³tese
Distribuir pods garante alta disponibilidade mas pode aumentar latÃªncia de rede entre nodes.

### BenefÃ­cios
âœ… Alta disponibilidade (falha de 1 node nÃ£o derruba serviÃ§o)  
âœ… Balanceamento de carga uniforme entre nodes  
âœ… Isolamento de falhas  

### Trade-offs
âŒ LatÃªncia inter-node (comunicaÃ§Ã£o cross-node)  
âŒ Overhead de rede  
âŒ Custo inicial 3x maior  

### ValidaÃ§Ã£o
```bash
# Verificar distribuiÃ§Ã£o (cada serviÃ§o em 3 nodes diferentes)
kubectl get pods -n pspd -o custom-columns=NAME:.metadata.name,NODE:.spec.nodeName
```

---

## ğŸ’° CenÃ¡rio 4: Recursos Limitados

**Arquivo**: `scenario4-resources/`

### ConfiguraÃ§Ã£o
- RÃ©plicas iniciais: 1
- HPA: âœ… Ativo e **mais agressivo**
  - CPU target: **60%** (vs 70% base) â¬‡ï¸
  - Max rÃ©plicas: **8-15** (vs 5-10 base) â¬†ï¸
- **Recursos reduzidos**:
  - CPU: **50m**/200m (vs 100m/500m) â¬‡ï¸ -50%/-60%
  - Memory: **64Mi**/128Mi (vs 128Mi/256Mi) â¬‡ï¸ -50%

### HipÃ³tese
Recursos limitados forÃ§am scaling horizontal agressivo. HPA compensa criando mais pods pequenos.

### Trade-offs
| Aspecto | Base | Recursos Limitados | Impacto |
|---------|------|-------------------|---------|
| CPU/pod | 500m | 200m | â¬‡ï¸ -60% |
| Pods spike | ~10 | ~18 (estimado) | â¬†ï¸ +80% |
| Throttling | Baixo | Alto | âš ï¸ |
| Custo/pod | Alto | Baixo | â¬‡ï¸ |
| Custo total | MÃ©dio | Similar | â‰ˆ |

### Quando usar
- âœ… Ambientes dev/staging com recursos limitados
- âœ… Testes de stress e resiliÃªncia
- âŒ ProduÃ§Ã£o sem validaÃ§Ã£o prÃ©via

---

## ğŸ”’ CenÃ¡rio 5: Sem HPA

**Arquivo**: `scenario5-no-hpa/`

### ConfiguraÃ§Ã£o
- RÃ©plicas: **FIXAS** (3 a/b, 5 p) - NÃƒO ESCALARÃ
- HPA: âŒ **DESABILITADO**
- Recursos: Mesmos do base

### HipÃ³tese
Sem HPA = over-provisioning constante. Paga pelo pior caso sempre.

### AnÃ¡lise de Custo

**CenÃ¡rio 1 (HPA)**:
```
Baseline: 3 pods Ã— 5min = 15 pod-min
Ramp:     6 pods Ã— 5min = 30 pod-min
Spike:   11 pods Ã— 2min = 22 pod-min
Soak:     7 pods Ã— 15min = 105 pod-min
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TOTAL: ~172 pod-min (2.9 pod-horas)
```

**CenÃ¡rio 5 (Sem HPA)**:
```
Todos os testes: 11 pods Ã— 27min = 297 pod-min (4.9 pod-horas)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
DESPERDÃCIO: +73% de custo
```

### Quando usar
- âœ… Carga extremamente previsÃ­vel e constante
- âœ… Debugging (sem variÃ¡veis de scaling)
- âŒ ProduÃ§Ã£o (anti-pattern moderno)

---

## ğŸ”„ Como Executar Cada CenÃ¡rio

### Passo 1: Limpar Ambiente

```bash
kubectl delete namespace pspd
kubectl create namespace pspd
```

### Passo 2: Aplicar CenÃ¡rio

```bash
# CenÃ¡rio 1 (Base)
kubectl apply -f k8s/namespace.yaml
kubectl apply -f k8s/a.yaml
kubectl apply -f k8s/b.yaml
kubectl apply -f k8s/p.yaml

# CenÃ¡rio 2 (RÃ©plicas)
kubectl apply -f k8s/namespace.yaml
kubectl apply -f k8s/scenarios/scenario2-replicas/

# CenÃ¡rio 3 (DistribuiÃ§Ã£o)
kubectl apply -f k8s/namespace.yaml
kubectl apply -f k8s/scenarios/scenario3-distribution/

# CenÃ¡rio 4 (Recursos)
kubectl apply -f k8s/namespace.yaml
kubectl apply -f k8s/scenarios/scenario4-resources/

# CenÃ¡rio 5 (Sem HPA)
kubectl apply -f k8s/namespace.yaml
kubectl apply -f k8s/scenarios/scenario5-no-hpa/
```

### Passo 3: Aguardar Pods

```bash
kubectl wait --for=condition=ready pod --all -n pspd --timeout=120s
```

### Passo 4: Executar Testes

```bash
./scripts/run_all_tests.sh all
```

### Passo 5: Salvar Resultados

```bash
# Renomear pasta de resultados
mv results/ results-scenario-X/
```

---

## ğŸ“Š Script Automatizado

Use o script `run_scenario_comparison.sh` para executar todos os cenÃ¡rios automaticamente:

```bash
./scripts/run_scenario_comparison.sh
```

Este script:
1. Executa cada cenÃ¡rio sequencialmente
2. Salva resultados em `results-scenario-{1-5}/`
3. Gera anÃ¡lise comparativa ao final
4. Cria grÃ¡ficos side-by-side

---

## ğŸ“ˆ MÃ©tricas de ComparaÃ§Ã£o

Para cada cenÃ¡rio, colete:

### Performance
- âœ… LatÃªncia P95 (baseline, ramp, spike, soak)
- âœ… Throughput mÃ©dio
- âœ… Taxa de sucesso/erro
- âœ… Tempo de resposta P50/P90/P95/P99

### Escalabilidade
- âœ… Tempo de scale-up (0â†’carga mÃ¡xima)
- âœ… Tempo de scale-down (carga mÃ¡ximaâ†’0)
- âœ… NÃºmero de rÃ©plicas (min/avg/max)
- âœ… Estabilidade do HPA

### Recursos
- âœ… CPU utilization mÃ©dia/pico
- âœ… Memory utilization mÃ©dia/pico
- âœ… Pods criados total
- âœ… Custo (pod*min)

### ResiliÃªncia
- âœ… Comportamento durante spike
- âœ… RecuperaÃ§Ã£o pÃ³s-spike
- âœ… Estabilidade durante soak

---

## ğŸ¯ Matriz de AnÃ¡lise Esperada

| CenÃ¡rio | LatÃªncia | Throughput | Custo | HA | Complexidade |
|---------|----------|------------|-------|-----|--------------|
| 1. Base | â­â­â­â­ | â­â­â­â­ | â­â­â­â­ | â­â­â­ | â­â­â­ |
| 2. RÃ©plicas | â­â­â­â­â­ | â­â­â­â­â­ | â­â­â­ | â­â­â­ | â­â­â­ |
| 3. DistribuiÃ§Ã£o | â­â­â­ | â­â­â­â­ | â­â­ | â­â­â­â­â­ | â­â­â­â­ |
| 4. Recursos | â­â­ | â­â­â­ | â­â­â­â­ | â­â­â­ | â­â­â­â­â­ |
| 5. Sem HPA | â­â­â­â­ | â­â­â­â­ | â­ | â­â­ | â­â­ |

**Legenda**: â­ = Ruim, â­â­â­â­â­ = Excelente

---

## ğŸ“ DocumentaÃ§Ã£o Detalhada

Cada cenÃ¡rio tem um `README.md` prÃ³prio com:
- âœ… ConfiguraÃ§Ã£o detalhada
- âœ… HipÃ³teses e objetivos
- âœ… Como executar
- âœ… MÃ©tricas esperadas
- âœ… AnÃ¡lise de trade-offs

Consulte os arquivos individuais em `scenarios/scenario{1-5}/README.md`.

---

## ğŸš€ PrÃ³ximos Passos

1. **Executar baseline** (CenÃ¡rio 1)
2. **Executar variaÃ§Ãµes** (CenÃ¡rios 2-5)
3. **Comparar resultados** (anÃ¡lise side-by-side)
4. **Documentar insights** (conclusÃµes e recomendaÃ§Ãµes)
5. **Gerar relatÃ³rio final** (com grÃ¡ficos comparativos)
