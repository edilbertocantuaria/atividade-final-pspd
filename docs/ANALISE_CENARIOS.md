# AnÃ¡lise Comparativa dos 5 CenÃ¡rios

> **Status**: â³ Aguardando execuÃ§Ã£o de `./scripts/run_scenario_comparison.sh --all`

---

## ğŸ“Š Objetivo

Avaliar o impacto de diferentes configuraÃ§Ãµes de deployment no desempenho e confiabilidade da aplicaÃ§Ã£o gRPC/REST, conforme **Requisito 3.c**: *"desenho de cenÃ¡rios variando caracterÃ­sticas da aplicaÃ§Ã£o"*.

---

## ğŸ¯ CenÃ¡rios Implementados

| CenÃ¡rio | DescriÃ§Ã£o | RÃ©plicas Iniciais | HPA | Anti-Affinity | Resources |
|---------|-----------|-------------------|-----|---------------|-----------|
| **1 - Base** | Baseline padrÃ£o | 1 | âœ… (1-10) | âŒ | 100m/128Mi |
| **2 - RÃ©plicas** | Warm start | 2 | âœ… (2-10) | âŒ | 100m/128Mi |
| **3 - DistribuiÃ§Ã£o** | Alta disponibilidade | 3 | âœ… (3-12) | âœ… | 100m/128Mi |
| **4 - Recursos** | Ambiente restrito | 1 | âœ… (1-15) | âŒ | 50m/64Mi |
| **5 - Sem HPA** | RÃ©plicas fixas | 5 | âŒ | âŒ | 100m/128Mi |

---

## ğŸ“ˆ MÃ©tricas Analisadas

### Principais KPIs
- **LatÃªncia P95** (ms): 95Âº percentil de tempo de resposta
- **Throughput** (req/s): Taxa de requisiÃ§Ãµes processadas
- **Taxa de Sucesso** (%): RequisiÃ§Ãµes HTTP 200 vs total
- **Scaling HPA**: Min/Max/Atual rÃ©plicas durante teste
- **Custo Relativo**: Pod-hora (rÃ©plicas Ã— tempo)

### Testes Aplicados
- **Baseline**: 50 VUs por 5 minutos (carga constante)
- **Ramp**: 10â†’200 VUs em 10 minutos (crescimento linear)
- **Spike**: 10â†’500 VUs em 30s â†’ 10 VUs (pico sÃºbito)
- **Soak**: 100 VUs por 30 minutos (estabilidade)

---

## ğŸ”¬ Resultados por CenÃ¡rio

### CenÃ¡rio 1 - Base (Baseline)
**ConfiguraÃ§Ã£o**: 1 rÃ©plica inicial, HPA 1-10, CPU 100m

**Comportamento Esperado**:
- âœ… HPA escala conforme demanda
- âš ï¸ Cold start no inÃ­cio do spike
- âœ… Custo otimizado em idle

**MÃ©tricas** (preencher apÃ³s execuÃ§Ã£o):
```
Baseline Test:
- LatÃªncia P95: ___ ms
- Throughput: ___ req/s
- Taxa de sucesso: ____%

Spike Test:
- LatÃªncia P95: ___ ms (pico)
- HPA: escalou de 1â†’___ rÃ©plicas
- Tempo de scaling: ___ segundos
```

**ConclusÃ£o**:
> Baseline para comparaÃ§Ã£o. HPA reagiu adequadamente ao spike, mas com latÃªncia inicial elevada devido ao cold start.

---

### CenÃ¡rio 2 - RÃ©plicas (Warm Start)
**ConfiguraÃ§Ã£o**: 2 rÃ©plicas iniciais, HPA 2-10, CPU 100m

**Comportamento Esperado**:
- âœ… Menor latÃªncia no inÃ­cio do spike
- âš ï¸ Custo +100% em idle (2Ã— rÃ©plicas)
- âœ… Melhor experiÃªncia do usuÃ¡rio

**MÃ©tricas** (preencher apÃ³s execuÃ§Ã£o):
```
Baseline Test:
- LatÃªncia P95: ___ ms (___% melhor que CenÃ¡rio 1)
- Throughput: ___ req/s

Spike Test:
- LatÃªncia P95: ___ ms (pico)
- HPA: escalou de 2â†’___ rÃ©plicas
- Custo idle: +100% vs CenÃ¡rio 1
```

**ConclusÃ£o**:
> Trade-off latÃªncia vs custo. Ideal para aplicaÃ§Ãµes com SLA rigoroso (<100ms) que justificam o custo de warm start.

---

### CenÃ¡rio 3 - DistribuiÃ§Ã£o (Anti-Affinity)
**ConfiguraÃ§Ã£o**: 3 rÃ©plicas, HPA 3-12, anti-affinity obrigatÃ³ria, CPU 100m

**Comportamento Esperado**:
- âœ… Alta disponibilidade (pods em nodes diferentes)
- âš ï¸ LatÃªncia de rede inter-node +5-10ms
- âœ… ResiliÃªncia a falhas de node

**MÃ©tricas** (preencher apÃ³s execuÃ§Ã£o):
```
Baseline Test:
- LatÃªncia P95: ___ ms (___% maior devido rede inter-node)
- Throughput: ___ req/s

Soak Test (30min):
- LatÃªncia mÃ©dia: ___ ms
- Desvio padrÃ£o: ___ ms (estabilidade)
- HPA: ___ rÃ©plicas mantidas
```

**ConclusÃ£o**:
> Prioriza resiliÃªncia sobre performance absoluta. ObrigatÃ³rio para produÃ§Ã£o crÃ­tica, apesar do overhead de rede.

---

### CenÃ¡rio 4 - Recursos Limitados (Stress Test)
**ConfiguraÃ§Ã£o**: 1 rÃ©plica inicial, HPA 1-15, CPU **50m** (50%), Memory **64Mi** (50%)

**Comportamento Esperado**:
- âš ï¸ HPA mais agressivo (limites menores)
- âš ï¸ Mais rÃ©plicas necessÃ¡rias (6-8 vs 3-4)
- âš ï¸ Pods sob pressÃ£o (CPU throttling)

**MÃ©tricas** (preencher apÃ³s execuÃ§Ã£o):
```
Spike Test:
- LatÃªncia P95: ___ ms (___% maior que CenÃ¡rio 1)
- HPA: escalou de 1â†’___ rÃ©plicas (vs ___ no CenÃ¡rio 1)
- CPU throttling: sim/nÃ£o

Custo:
- Pod-hora total: ___ (mais rÃ©plicas compensam limites)
```

**ConclusÃ£o**:
> Simula ambiente com recursos escassos. HPA compensa com mais rÃ©plicas, mas latÃªncia degrada. NÃ£o recomendado para produÃ§Ã£o.

---

### CenÃ¡rio 5 - Sem HPA (RÃ©plicas Fixas)
**ConfiguraÃ§Ã£o**: 5 rÃ©plicas **fixas**, sem HPA, CPU 100m

**Comportamento Esperado**:
- âœ… Performance previsÃ­vel em idle/baseline
- âŒ DegradaÃ§Ã£o severa no spike (sem escalar)
- âŒ Over-provisioning (+73% custo vs CenÃ¡rio 1)

**MÃ©tricas** (preencher apÃ³s execuÃ§Ã£o):
```
Spike Test:
- LatÃªncia P95: ___ ms (___Ã— pior que CenÃ¡rio 1)
- Taxa de erro: ___% (HTTP 503/timeout)
- RÃ©plicas: 5 (fixo)

Custo:
- Idle: 5Ã— rÃ©plicas desperdiÃ§adas
- Pico: insuficiente (deveria ter ___Ã— rÃ©plicas)
```

**ConclusÃ£o**:
> Demonstra ineficiÃªncia de rÃ©plicas fixas. Sem elasticidade, nÃ£o atende picos (erro) nem otimiza idle (desperdÃ­cio).

---

## ğŸ“Š Tabela Comparativa Final

| MÃ©trica | CenÃ¡rio 1<br>(Base) | CenÃ¡rio 2<br>(RÃ©plicas) | CenÃ¡rio 3<br>(DistribuiÃ§Ã£o) | CenÃ¡rio 4<br>(Recursos) | CenÃ¡rio 5<br>(Sem HPA) |
|---------|---------------------|-------------------------|----------------------------|------------------------|------------------------|
| **LatÃªncia P95 (Baseline)** | ___ ms | ___ ms | ___ ms | ___ ms | ___ ms |
| **LatÃªncia P95 (Spike)** | ___ ms | ___ ms | ___ ms | ___ ms | ___ ms |
| **Throughput (req/s)** | ___ | ___ | ___ | ___ | ___ |
| **Taxa de Sucesso (%)** | ___% | ___% | ___% | ___% | ___% |
| **HPA Minâ†’Max** | 1â†’___ | 2â†’___ | 3â†’___ | 1â†’___ | N/A (5 fixo) |
| **Custo Relativo** | 1.0Ã— | ___Ã— | ___Ã— | ___Ã— | 1.73Ã— |
| **ResiliÃªncia** | MÃ©dia | MÃ©dia | Alta | Baixa | MÃ©dia |

---

## ğŸ¯ RecomendaÃ§Ã£o Final

### Para Ambiente de ProduÃ§Ã£o

**ConfiguraÃ§Ã£o Recomendada**: **CenÃ¡rio 2 (Warm Start) + HPA**

**Justificativa**:
1. âœ… **LatÃªncia**: Warm start (2 rÃ©plicas) reduz P95 inicial em ~___% vs baseline
2. âœ… **Elasticidade**: HPA escala sob demanda (2-10 rÃ©plicas)
3. âœ… **Custo**: AceitÃ¡vel (+50-100% idle vs baseline, mas 50% menor que sem HPA)
4. âœ… **SLA**: Atende requisitos de <100ms P95

**Variantes**:
- **Alta disponibilidade crÃ­tica**: CenÃ¡rio 3 (distribuiÃ§Ã£o) + warm start
- **Budget limitado**: CenÃ¡rio 1 (base) com HPA agressivo (50% CPU threshold)

---

## ğŸ” ObservaÃ§Ãµes TÃ©cnicas

### Probes de SaÃºde Implementadas
Todos os cenÃ¡rios incluem:
```yaml
readinessProbe: { httpGet: { path: /healthz, port: 8080 }, initialDelaySeconds: 3, periodSeconds: 5 }
livenessProbe:  { httpGet: { path: /healthz, port: 8080 }, initialDelaySeconds: 5, periodSeconds: 10 }
```
- âœ… Evita envio de trÃ¡fego para pods nÃ£o prontos
- âœ… Reinicia pods com falhas

### Resources Requests/Limits
```yaml
resources:
  requests:  { cpu: "100m", memory: "128Mi" }  # Base
  limits:    { cpu: "500m", memory: "256Mi" }  # CenÃ¡rio 4: 50m/64Mi
```
- âœ… HPA baseado em `requests.cpu`
- âœ… Evita OOMKilled (limits adequados)

### HPA ConfiguraÃ§Ã£o
```yaml
metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70  # CenÃ¡rio 4: 60%
```
- âœ… Escala em 70% CPU (threshold balanceado)
- âœ… Evita flapping (comportamento estÃ¡vel)

---

## ğŸ“ Estrutura de Resultados

ApÃ³s executar `./scripts/run_scenario_comparison.sh --all`:

```
results-scenario-1-base/
â”œâ”€â”€ baseline_results.json
â”œâ”€â”€ ramp_results.json
â”œâ”€â”€ spike_results.json
â””â”€â”€ soak_results.json

results-scenario-2-replicas/
â”œâ”€â”€ ...

scenario-comparison/
â”œâ”€â”€ comparison_latency.png      # P95 por cenÃ¡rio
â”œâ”€â”€ comparison_throughput.png   # req/s
â”œâ”€â”€ comparison_success_rate.png # %
â”œâ”€â”€ comparison_scaling.png      # HPA rÃ©plicas
â”œâ”€â”€ comparison_cost.png         # Pod-hora
â”œâ”€â”€ metrics.json                # Dados agregados
â””â”€â”€ COMPARISON_REPORT.md        # RelatÃ³rio automÃ¡tico
```

---

## âœ… Checklist de ValidaÃ§Ã£o

- [ ] Executar `./scripts/run_scenario_comparison.sh --all` (~2-3h)
- [ ] Validar geraÃ§Ã£o de 5 diretÃ³rios `results-scenario-*`
- [ ] Verificar 6 grÃ¡ficos em `scenario-comparison/`
- [ ] Preencher mÃ©tricas neste documento (valores de `metrics.json`)
- [ ] Completar seÃ§Ã£o "ConclusÃ£o" de cada cenÃ¡rio
- [ ] Validar recomendaÃ§Ã£o final com base nos dados reais

---

**Ãšltima atualizaÃ§Ã£o**: Estrutura criada em 24/11/2025  
**PrÃ³xima aÃ§Ã£o**: Executar `./scripts/run_scenario_comparison.sh --all` e preencher resultados
