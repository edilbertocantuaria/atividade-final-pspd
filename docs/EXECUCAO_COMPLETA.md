# ğŸš€ GUIA DE EXECUÃ‡ÃƒO COMPLETA - TODOS OS TESTES

> **Este Ã© o ÃšNICO arquivo que vocÃª precisa ler para executar TUDO do zero ao fim.**

---

## ğŸ“Œ O QUE ESTE GUIA FAZ

Executa **TODOS** os testes cobrindo **TODOS** os requisitos acadÃªmicos:

âœ… **Cluster Kubernetes Multi-Node** (1 master + 2 workers)  
âœ… **Prometheus instalado no K8s** (via Helm)  
âœ… **Interface Web de Monitoramento** (Grafana com dashboard customizado)  
âœ… **5 CenÃ¡rios de Teste de Carga** (baseline, ramp, spike, stress, soak)  
âœ… **MÃ©tricas e GrÃ¡ficos** (anÃ¡lise automatizada com Python)  
âœ… **Sistema de Checkpoints** (continua de onde parou em caso de erro)

---

## âš¡ EXECUÃ‡ÃƒO RÃPIDA (4 COMANDOS)

### ğŸ”´ IMPORTANTE: DiferenÃ§a entre os scripts

- **`./RUN_COMPLETE.sh`** = **SETUP DO AMBIENTE** (executar 1 vez)
  - Cria cluster Kubernetes multi-node
  - Instala Prometheus + Grafana
  - Faz build e deploy das aplicaÃ§Ãµes
  - **Execute apenas UMA VEZ** ou apÃ³s deletar o cluster

- **`./scripts/run_all_tests.sh all`** = **TESTES DE CARGA** (pode executar vÃ¡rias vezes)
  - Executa os 4 testes de carga
  - Coleta mÃ©tricas e logs
  - **Pode executar QUANTAS VEZES QUISER** sem refazer o setup

---

### Primeira ExecuÃ§Ã£o (do zero):

```bash
# 1ï¸âƒ£ Setup completo (cluster + apps + Prometheus + Grafana) - 5-10 min
#    âš ï¸ Execute apenas UMA VEZ
./RUN_COMPLETE.sh

# 2ï¸âƒ£ Em OUTRO terminal: Port-forward estÃ¡vel
#    âš ï¸ Deixe rodando durante os testes
./scripts/stable_port_forward.sh

# 3ï¸âƒ£ Executar TODOS os testes - 15-20 min
#    âœ… Pode executar VÃRIAS VEZES sem refazer o setup
./scripts/run_all_tests.sh all
# Aguarde 15s (ou pressione Enter) para executar stress e soak automaticamente

# 4ï¸âƒ£ Gerar grÃ¡ficos e anÃ¡lise
python3 scripts/analyze_results.py
```

### ExecuÃ§Ãµes Subsequentes (cluster jÃ¡ existe):

```bash
# âŒ NÃƒO precisa executar ./RUN_COMPLETE.sh novamente!
# âœ… Apenas rode os testes quantas vezes quiser:

./scripts/stable_port_forward.sh     # Se nÃ£o estiver rodando
./scripts/run_all_tests.sh all       # Testes novamente
python3 scripts/analyze_results.py   # Novos grÃ¡ficos
```

âœ… **Pronto!** Todos os resultados estarÃ£o em `results/`

---

## ğŸ“– EXECUÃ‡ÃƒO DETALHADA (PASSO A PASSO)

### ETAPA 1: PreparaÃ§Ã£o do Ambiente

```bash
# Garantir que estÃ¡ no diretÃ³rio correto
cd atividade-final-pspd

# Verificar dependÃªncias
which minikube kubectl helm docker k6 python3
# Se algo faltar, instale antes de continuar
```

**DependÃªncias necessÃ¡rias:**
- minikube (versÃ£o 1.34+)
- kubectl (versÃ£o 1.30+)
- helm (versÃ£o 3.0+)
- docker (para builds)
- k6 (para testes de carga)
- python3 + pip (para anÃ¡lise)

---

### ETAPA 2: Criar Cluster Multi-Node

```bash
# OpÃ§Ã£o A: Script automatizado (RECOMENDADO)
./RUN_COMPLETE.sh
# Este script tem checkpoints - se falhar, pode executar novamente que continua de onde parou

# OpÃ§Ã£o B: Passo a passo manual
./scripts/setup_multinode_cluster.sh    # Cria cluster 1+2
./scripts/deploy.sh setup                # Deploy das apps
./scripts/deploy.sh monitoring           # Configura Prometheus
```

**O que acontece:**
1. Cria cluster minikube com 3 nÃ³s (1 master + 2 workers)
2. Instala Helm se nÃ£o estiver presente
3. Instala kube-prometheus-stack (Prometheus + Grafana + Alertmanager)
4. Faz build das 3 imagens Docker (gateway-p, service-a, service-b)
5. Carrega imagens em todos os nÃ³s do cluster
6. Faz deploy de todos os deployments, services, HPAs
7. Configura 3 ServiceMonitors para scraping automÃ¡tico
8. ExpÃµe Prometheus (NodePort 30090) e Grafana (NodePort 31510)
9. Importa dashboard customizado no Grafana

**Tempo estimado:** 5-10 minutos (primeira vez)

**ValidaÃ§Ã£o:**
```bash
# Verificar cluster
minikube profile list
kubectl get nodes

# Verificar pods
kubectl get pods -n pspd
kubectl get pods -n monitoring

# Verificar serviÃ§os
kubectl get svc -n pspd
kubectl get svc -n monitoring

# Todos os pods devem estar Running/Completed
```

---

### ETAPA 3: Configurar Port-Forwards

```bash
# Em um TERMINAL SEPARADO, deixe rodando:
./scripts/stable_port_forward.sh
```

**O que faz:**
- Port-forward para Prometheus: `http://localhost:9090`
- Port-forward para Grafana: `http://localhost:3000`
- Port-forward para Gateway P: `http://localhost:8080`
- Auto-restart em caso de queda (Ãºtil durante testes pesados)

**ValidaÃ§Ã£o:**
```bash
# Em outro terminal:
curl http://localhost:8080          # Gateway P
curl http://localhost:9090/-/ready  # Prometheus
curl http://localhost:3000/api/health  # Grafana
```

---

### ETAPA 4: Acessar Grafana e Dashboard

1. **Abrir navegador:** `http://localhost:3000`
2. **Login:**
   - UsuÃ¡rio: `admin`
   - Senha: `admin` (pode pular alteraÃ§Ã£o)
3. **Dashboard:**
   - Menu lateral â†’ Dashboards â†’ "PSPD - Microservices Observability"

**Painel do Dashboard (7 grÃ¡ficos):**
- HTTP Request Rate (req/s)
- HTTP Request Duration P95 (ms)
- CPU Usage (%)
- Memory Usage (MB)
- Pod Replicas
- HTTP Error Rate (%)
- gRPC Request Duration P95 (ms)

---

### ETAPA 5: Executar TODOS os Testes

```bash
# TERMINAL PRINCIPAL (nÃ£o o do port-forward):
./scripts/run_all_tests.sh all
```

**ğŸ’¡ Executar testes individuais:**

```bash
# Apenas um teste especÃ­fico:
./scripts/run_all_tests.sh baseline   # 30s
./scripts/run_all_tests.sh ramp       # 90s
./scripts/run_all_tests.sh spike      # 30s
./scripts/run_all_tests.sh soak       # 11 min
```

**SequÃªncia automÃ¡tica:**

1. **Baseline** (30s)
   - 10 VUs constantes
   - ValidaÃ§Ã£o: taxa erro < 1%, p95 < 500ms

2. **Ramp** (90s)
   - 10 â†’ 150 VUs gradual
   - ValidaÃ§Ã£o: HPA escala pods

3. **Spike** (30s)
   - 10 â†’ 200 VUs sÃºbito
   - ValidaÃ§Ã£o: resiliÃªncia sob carga extrema (pode ter erros)

4. **Soak** (11 minutos) - *Aguarda 15s ou pressione Enter*
   - 50 VUs por 10 minutos
   - ValidaÃ§Ã£o: estabilidade prolongada

**Comportamento padrÃ£o:**
- Se nÃ£o responder nada, **EXECUTA TUDO** automaticamente
- Para pular stress ou soak: digite `n` antes dos 15s

**Tempo total:** 15-20 minutos (com todos os testes)

**O que Ã© coletado durante os testes:**
- MÃ©tricas JSON do k6 (`results/{test}/metrics.json`)
- Logs de execuÃ§Ã£o (`results/{test}/output.txt`)
- Snapshots de pods antes/depois (`results/{test}/pod-metrics-{pre|post}.txt`)
- Status do HPA (`results/{test}/hpa-status-{pre|post}.txt`)
- Eventos do K8s (apenas spike: `results/{test}/events.txt`)

---

### ETAPA 6: Analisar Resultados

```bash
# Gerar grÃ¡ficos e anÃ¡lise estatÃ­stica
python3 scripts/analyze_results.py
```

**SaÃ­das geradas em `results/plots/`:**

1. **response_times_comparison.png**
   - ComparaÃ§Ã£o de latÃªncias (p50, p95, p99) entre todos os testes

2. **throughput_comparison.png**
   - Requests por segundo de cada teste

3. **error_rates.png**
   - Taxa de erro (%) por teste

4. **{test}_timeline.png** (para cada teste)
   - EvoluÃ§Ã£o temporal: latÃªncia, throughput, erros

5. **hpa_scaling.png**
   - EvoluÃ§Ã£o do nÃºmero de rÃ©plicas durante os testes

6. **resource_usage.png**
   - CPU e memÃ³ria dos pods ao longo do tempo

**Resumo em texto:** `results/test_summary.txt`

---

## ğŸ“Š RESULTADOS ESPERADOS

### Testes Sem Erros (baseline, ramp, spike, soak)

```
Baseline:  10 VUs Ã— 30s   â†’ p95 < 500ms, erro = 0%
Ramp:      10â†’150 VUs     â†’ p95 < 1s,    erro = 0%, HPA escala
Spike:     10â†’200 VUs     â†’ p95 < 2s,    erro < 10%, recuperaÃ§Ã£o rÃ¡pida
Soak:      50 VUs Ã— 10min â†’ p95 < 800ms, erro = 0%, sem memory leak
```

### Teste Stress (opcional, pode ter erros)

```
Stress:    10â†’200 VUs     â†’ p95 < 2s, erro < 50%, identifica limite
```

**Indicadores de sucesso:**
- âœ… HPA escalou de 1 para 3+ rÃ©plicas durante ramp/spike
- âœ… Pods retornaram a 1 rÃ©plica apÃ³s testes
- âœ… Taxa de erro = 0% em baseline, ramp e soak
- âœ… Taxa de erro < 10% no spike (carga extrema)
- âœ… P95 abaixo dos thresholds definidos
- âœ… Prometheus coletou mÃ©tricas de todos os serviÃ§os
- âœ… Grafana mostra grÃ¡ficos em tempo real

---

## ğŸ” VERIFICAÃ‡ÃƒO E TROUBLESHOOTING

### Verificar Estado do Sistema

```bash
# Pods rodando
kubectl get pods -n pspd
# Deve mostrar: gateway-p, service-a, service-b (Running)

# HPA funcionando
kubectl get hpa -n pspd
# Deve mostrar 3 HPAs com TARGETS preenchidos

# Prometheus scraping
kubectl logs -n monitoring -l app.kubernetes.io/name=prometheus -c prometheus | grep "pspd"
# Deve mostrar scrapes bem-sucedidos

# ServiceMonitors
kubectl get servicemonitor -n pspd
# Deve mostrar: gateway-p-monitor, service-a-monitor, service-b-monitor
```

### Problemas Comuns

**1. Port-forward cai durante teste spike/stress**
- âœ… **Normal!** O script `stable_port_forward.sh` reinicia automaticamente
- Aguarde 5-10 segundos, ele reconecta sozinho

**2. "ServiÃ§o nÃ£o acessÃ­vel em http://localhost:8080"**
```bash
# Verificar se port-forward estÃ¡ rodando
ps aux | grep "port-forward"

# Se nÃ£o estiver, executar em terminal separado:
./scripts/stable_port_forward.sh
```

**3. Pods nÃ£o escalam durante ramp**
```bash
# Verificar HPA
kubectl describe hpa -n pspd

# Verificar metrics-server
kubectl top pods -n pspd

# Se mÃ©tricas nÃ£o aparecem, esperar 1-2 minutos (warm-up)
```

**4. Teste spike causa erros (~33%)**
- âœ… **Normal!** Spike de 200 VUs testa limite do sistema
- Sistema deve se recuperar apÃ³s o pico
- Para relatÃ³rio: mostre a capacidade de recuperaÃ§Ã£o

**5. Teste stress causa muitos erros (>50%)**
- âœ… **Esperado!** Stress encontra o limite absoluto
- Use stress apenas para anÃ¡lise de capacidade mÃ¡xima

**6. Grafana nÃ£o carrega dashboard**
```bash
# Reimportar dashboard
./scripts/deploy.sh monitoring

# Ou acessar Grafana e importar manualmente:
# Dashboards â†’ Import â†’ Colar JSON de k8s/grafana-dashboard.json
```

---

## ğŸ“ ESTRUTURA DE RESULTADOS

ApÃ³s execuÃ§Ã£o completa:

```
results/
â”œâ”€â”€ baseline/
â”‚   â”œâ”€â”€ metrics.json          # Dados brutos k6
â”‚   â”œâ”€â”€ output.txt            # Log do teste
â”‚   â”œâ”€â”€ pod-metrics-pre.txt   # Recursos antes
â”‚   â””â”€â”€ pod-metrics-post.txt  # Recursos depois
â”œâ”€â”€ ramp/
â”œâ”€â”€ spike/
â”‚   â””â”€â”€ events.txt            # Eventos K8s (HPA scaling)
â”œâ”€â”€ stress/
â”œâ”€â”€ soak/
â”œâ”€â”€ plots/                    # GRÃFICOS GERADOS
â”‚   â”œâ”€â”€ response_times_comparison.png
â”‚   â”œâ”€â”€ throughput_comparison.png
â”‚   â”œâ”€â”€ error_rates.png
â”‚   â”œâ”€â”€ baseline_timeline.png
â”‚   â”œâ”€â”€ ramp_timeline.png
â”‚   â”œâ”€â”€ spike_timeline.png
â”‚   â”œâ”€â”€ stress_timeline.png
â”‚   â”œâ”€â”€ soak_timeline.png
â”‚   â”œâ”€â”€ hpa_scaling.png
â”‚   â””â”€â”€ resource_usage.png
â”œâ”€â”€ test_summary.txt          # Resumo estatÃ­stico
â”œâ”€â”€ hpa-final.yaml            # ConfiguraÃ§Ã£o HPA final
â”œâ”€â”€ pods-final.txt            # Estado final dos pods
â”œâ”€â”€ prometheus-metrics.txt    # Snapshot de mÃ©tricas
â””â”€â”€ gateway-logs.txt          # Logs das aplicaÃ§Ãµes
```

---

## ğŸ¯ CHECKLIST COMPLETO

### Antes de Iniciar
- [ ] DependÃªncias instaladas (minikube, kubectl, helm, docker, k6, python3)
- [ ] Docker daemon rodando
- [ ] Pelo menos 8GB RAM disponÃ­vel
- [ ] Pelo menos 20GB disco disponÃ­vel

### ExecuÃ§Ã£o
- [ ] Cluster multi-node criado (1+2 nÃ³s)
- [ ] Prometheus instalado e rodando
- [ ] Grafana acessÃ­vel com dashboard
- [ ] Port-forwards ativos (terminal separado)
- [ ] Teste baseline executado (0% erro)
- [ ] Teste ramp executado (HPA escalou)
- [ ] Teste spike executado (0% erro)
- [ ] Teste stress executado (limite encontrado)
- [ ] Teste soak executado (estabilidade confirmada)
- [ ] AnÃ¡lise Python executada (grÃ¡ficos gerados)

### ValidaÃ§Ã£o Final
- [ ] 10+ arquivos PNG em `results/plots/`
- [ ] `test_summary.txt` com estatÃ­sticas
- [ ] Todos os testes com p95 dentro dos limites
- [ ] HPA escalou e voltou ao normal
- [ ] Prometheus coletando mÃ©tricas de 3 serviÃ§os
- [ ] Grafana mostrando dados em tempo real

---

## ğŸ“ PARA O RELATÃ“RIO ACADÃŠMICO

**Use estes resultados:**

1. **Arquitetura:**
   - Diagrama do cluster multi-node (README.md)
   - Print do `kubectl get nodes`
   - Print do Grafana dashboard

2. **Monitoramento:**
   - Print do Prometheus Targets (todos UP)
   - Print do Grafana mostrando mÃ©tricas
   - ServiceMonitors configurados

3. **Testes de Carga:**
   - Tabela comparativa de `test_summary.txt`
   - GrÃ¡ficos de `results/plots/`
   - Foco em: baseline, ramp, spike, soak

4. **Escalabilidade:**
   - `hpa_scaling.png` mostrando auto-scaling
   - Prints de `kubectl get hpa` durante ramp
   - ComparaÃ§Ã£o de latÃªncia 1 vs 3 rÃ©plicas

5. **ConclusÃµes:**
   - Sistema escala automaticamente com HPA
   - Prometheus + Grafana permitem observabilidade completa
   - Cluster multi-node distribui carga entre workers
   - Todos os testes passaram nos thresholds

---

## ğŸ“ COMANDOS ÃšTEIS

### Executar Testes Individuais

```bash
# Todos os testes (15-20 min)
./scripts/run_all_tests.sh all

# Testes individuais:
./scripts/run_all_tests.sh baseline   # 30s - Carga constante
./scripts/run_all_tests.sh ramp       # 90s - Escalonamento gradual
./scripts/run_all_tests.sh spike      # 30s - Pico sÃºbito
./scripts/run_all_tests.sh stress     # 90s - Limite mÃ¡ximo
./scripts/run_all_tests.sh soak       # 11min - Estabilidade prolongada
```

### Monitoramento em Tempo Real

```bash
# Ver logs em tempo real durante testes
kubectl logs -f -n pspd -l app=p

# Monitorar HPA
watch -n 2 kubectl get hpa -n pspd

# Ver eventos de scaling
kubectl get events -n pspd --sort-by='.lastTimestamp' | grep -i scale

# Consultar Prometheus direto
curl 'http://localhost:9090/api/v1/query?query=up'
```

### Gerenciamento do Cluster

```bash
# Reiniciar tudo do zero
minikube delete -p pspd-cluster
./RUN_COMPLETE.sh

# Parar cluster (sem deletar)
minikube stop -p pspd-cluster

# Iniciar cluster parado
minikube start -p pspd-cluster
```

---

## âœ… RESUMO: 4 COMANDOS PARA TUDO

### ğŸ”´ Primeira Vez (ou apÃ³s `minikube delete`):

```bash
# 1. Setup (UMA VEZ) - Cria cluster + instala Prometheus + deploy apps
./RUN_COMPLETE.sh

# 2. Port-forward (terminal separado) - Deixe rodando
./scripts/stable_port_forward.sh

# 3. Testes (pode executar VÃRIAS VEZES) - Coleta mÃ©tricas
./scripts/run_all_tests.sh all

# 4. AnÃ¡lise (apÃ³s cada execuÃ§Ã£o de testes) - Gera grÃ¡ficos
python3 scripts/analyze_results.py
```

### ğŸŸ¢ ExecuÃ§Ãµes Seguintes (cluster jÃ¡ existe):

```bash
# âŒ NÃƒO execute ./RUN_COMPLETE.sh novamente!
# âœ… Apenas os testes:

./scripts/run_all_tests.sh all       # Quantas vezes quiser
python3 scripts/analyze_results.py   # Atualizar grÃ¡ficos
```

---

**Analogia simples:**
- `RUN_COMPLETE.sh` = **construir a casa** ğŸ—ï¸ (uma vez)
- `run_all_tests.sh` = **testar a casa** ğŸ”¬ (quantas vezes quiser)

**Pronto! VocÃª tem TUDO necessÃ¡rio para o trabalho acadÃªmico.** ğŸ“âœ¨
